{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "654d79d0-3287-4d12-b5f1-8a011f40e3a5",
   "metadata": {},
   "source": [
    "PySpark Assignment: Data Cleaning, Transformation, Analysis, and Prediction\n",
    "\n",
    "Student:Angel Ivan Reyes Torresa ID: C0053883\n",
    "\n",
    "Dataset Info: NBrewery Operations and Market Analysis Dat\n",
    "\n",
    "2.6 GB\n",
    "\n",
    "Total rows in dataset: 10,000,000\n",
    "\n",
    "https://www.kaggle.com/datasets/ankurnapa/brewery-operations-and-market-analysis-dataset?select=brewery_data_complete_extended.csv\n",
    "\n",
    "This dataset presents an extensive collection of data from a craft beer brewery, spanning from January 2020 to January 2024. It encapsulates a rich blend of brewing parameters, sales data, and quality assessments, providing a holistic view of the brewing process and its market implications.\n",
    "\n",
    "Contain 20 columnsong others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d490df16-78e2-4072-9271-9733bba63aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from functools import reduce\n",
    "import matplotlib.pyplot as plt\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.ml.feature import StringIndexer, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from pyspark.ml.classification import LinearSVC\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pyspark.ml.regression import RandomForestRegressor\n",
    "from pyspark.ml.feature import StringIndexer, VectorAssembler, StandardScaler\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder, ParamGridBuilder\n",
    "from pyspark.sql.types import FloatType, DoubleType, IntegerType\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator, BinaryClassificationEvaluator, RegressionEvaluator\n",
    "from pyspark.sql.functions import col, count, when, isnan, to_date, year, month, dayofweek, dayofyear, avg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11de8094-b5e6-4c41-8b5f-2ec95a644b37",
   "metadata": {},
   "source": [
    "1 Data Loading and Initial Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "305be14d-e646-48ab-b26e-35e69c96757b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start a Spark session with optimized configurations for handling large datasets\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"BreweryDataAnalysis\") \\\n",
    "    .config(\"spark.driver.memory\", \"16g\") \\\n",
    "    .config(\"spark.executor.memory\", \"16g\") \\\n",
    "    .config(\"spark.sql.shuffle.partitions\", \"100\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "caf373c8-831b-4c2f-a90b-6a96b701469e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset with an appropriate number of partitions\n",
    "file_path = \"C:/Users/angel/00Angel/brewery_data.csv\"\n",
    "df = spark.read.csv(file_path, header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "22fba1e8-682f-4c68-88f9-2b2cce3e6510",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Batch_ID: integer (nullable = true)\n",
      " |-- Brew_Date: timestamp (nullable = true)\n",
      " |-- Beer_Style: string (nullable = true)\n",
      " |-- SKU: string (nullable = true)\n",
      " |-- Location: string (nullable = true)\n",
      " |-- Fermentation_Time: integer (nullable = true)\n",
      " |-- Temperature: double (nullable = true)\n",
      " |-- pH_Level: double (nullable = true)\n",
      " |-- Gravity: double (nullable = true)\n",
      " |-- Alcohol_Content: double (nullable = true)\n",
      " |-- Bitterness: integer (nullable = true)\n",
      " |-- Color: integer (nullable = true)\n",
      " |-- Ingredient_Ratio: string (nullable = true)\n",
      " |-- Volume_Produced: integer (nullable = true)\n",
      " |-- Total_Sales: double (nullable = true)\n",
      " |-- Quality_Score: double (nullable = true)\n",
      " |-- Brewhouse_Efficiency: double (nullable = true)\n",
      " |-- Loss_During_Brewing: double (nullable = true)\n",
      " |-- Loss_During_Fermentation: double (nullable = true)\n",
      " |-- Loss_During_Bottling_Kegging: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check the schema to see data types and structure\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ea7a487c-26cd-46df-889a-904403205d47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------------------+----------+-------+---------------+-----------------+------------------+------------------+------------------+-----------------+----------+-----+----------------+---------------+------------------+-----------------+--------------------+-------------------+------------------------+----------------------------+\n",
      "|Batch_ID|Brew_Date          |Beer_Style|SKU    |Location       |Fermentation_Time|Temperature       |pH_Level          |Gravity           |Alcohol_Content  |Bitterness|Color|Ingredient_Ratio|Volume_Produced|Total_Sales       |Quality_Score    |Brewhouse_Efficiency|Loss_During_Brewing|Loss_During_Fermentation|Loss_During_Bottling_Kegging|\n",
      "+--------+-------------------+----------+-------+---------------+-----------------+------------------+------------------+------------------+-----------------+----------+-----+----------------+---------------+------------------+-----------------+--------------------+-------------------+------------------------+----------------------------+\n",
      "|7870796 |2020-01-01 00:00:19|Wheat Beer|Kegs   |Whitefield     |16               |24.204250857069873|5.2898454476095615|1.0395041267301979|5.370842159553436|20        |5    |1:0.32:0.16     |4666           |2664.7593448382822|8.57701633109399 |89.19588216376087   |4.1049876591878345 |3.2354851724654683      |4.663204448186049           |\n",
      "|9810411 |2020-01-01 00:00:31|Sour      |Kegs   |Whitefield     |13               |18.086762947259544|5.275643382756193 |1.0598189516987164|5.096053082797625|36        |14   |1:0.39:0.24     |832            |9758.801062471319 |7.420540752553908|72.4809153900275    |2.6765280953921122 |4.2461292104108574      |2.04435836917023            |\n",
      "|2623342 |2020-01-01 00:00:40|Wheat Beer|Kegs   |Malleswaram    |12               |15.539332669116469|4.7780156232459765|1.0374757095487201|4.824737120959184|30        |10   |1:0.35:0.16     |2115           |11721.087016274963|8.451364886803127|86.32214396020584   |3.299893625514981  |3.109440467362847       |3.0338798378762806          |\n",
      "|8114651 |2020-01-01 00:01:37|Ale       |Kegs   |Rajajinagar    |17               |16.41848910394318 |5.345260585546188 |1.0524314251694946|5.509243080797997|48        |18   |1:0.35:0.15     |3173           |12050.177463190277|9.671859404043175|83.09494037181545   |2.136055116262562  |4.634254174098425       |1.4898890677148424          |\n",
      "|4579587 |2020-01-01 00:01:43|Stout     |Cans   |Marathahalli   |18               |19.144907654338517|4.86185374113861  |1.0542961149482333|5.133624684263243|57        |13   |1:0.46:0.11     |4449           |5515.0774647529615|7.895333676172065|88.62583302052388   |4.491723843594972  |2.1833886016455497      |2.9906302188791485          |\n",
      "|8715759 |2020-01-01 00:01:48|Ale       |Kegs   |Whitefield     |10               |17.424614393375766|5.291786621908058 |1.064662042682204 |4.859171021614226|45        |9    |1:0.23:0.15     |3752           |6278.389850288936 |8.47381192497374 |87.8128259096688    |3.2051089361121203 |1.4783386754434935      |3.051920588503346           |\n",
      "|6441292 |2020-01-01 00:01:49|Lager     |Pints  |Electronic City|16               |15.629810875902074|5.3328812410204325|1.0466885050091976|4.710402522822796|44        |8    |1:0.34:0.16     |593            |14362.653665879505|6.958182685507612|85.73496269913532   |3.955331969978375  |1.6229792325278112      |1.566344313315546           |\n",
      "|8843420 |2020-01-01 00:01:51|Wheat Beer|Cans   |Indiranagar    |13               |21.605469689190052|4.507213419450749 |1.0415809900303394|4.83702482975061 |38        |9    |1:0.45:0.26     |4949           |1082.3549117830858|6.295632960105362|73.43876487534912   |1.7047005571803084 |1.7187729863809476      |1.0336558740315214          |\n",
      "|5713096 |2020-01-01 00:02:16|Stout     |Bottles|Electronic City|18               |20.183530075814367|5.224481542948347 |1.0764413828584096|5.133596661986578|25        |15   |1:0.39:0.19     |2451           |7392.644809330611 |9.660185081725519|83.26770612274336   |4.765479207857815  |2.3862457622492697      |4.453829514148623           |\n",
      "|8178852 |2020-01-01 00:02:32|Stout     |Cans   |Electronic City|11               |17.237974924919577|4.911261716318917 |1.0478298509908957|5.709899253603638|48        |10   |1:0.43:0.17     |4305           |7648.2830929155325|9.348719159247096|73.60380329779937   |3.8425385336431    |4.284796713900535       |1.3128481660547955          |\n",
      "+--------+-------------------+----------+-------+---------------+-----------------+------------------+------------------+------------------+-----------------+----------+-----+----------------+---------------+------------------+-----------------+--------------------+-------------------+------------------------+----------------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Show the first 10 rows to inspect data quality and format\n",
    "df.show(10, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "33d399d5-7d78-4e2b-8dc0-b46d55513f52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows in dataset: 10000000\n"
     ]
    }
   ],
   "source": [
    "# Count the total number of rows in the dataset\n",
    "row_count = df.count()\n",
    "print(f\"Total rows in dataset: {row_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89642a1d-a9aa-4eae-9b12-bc06614a1e9c",
   "metadata": {},
   "source": [
    "2 Data Cleaning and Transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bf1ff2c-f5e4-4106-b650-c77a430f0c13",
   "metadata": {},
   "source": [
    "2.1. Handling Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "96b56a20-8e35-4d57-aa74-0c2adb4593e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---------+----------+---+--------+-----------------+-----------+--------+-------+---------------+----------+-----+----------------+---------------+-----------+-------------+--------------------+-------------------+------------------------+----------------------------+\n",
      "|Batch_ID|Brew_Date|Beer_Style|SKU|Location|Fermentation_Time|Temperature|pH_Level|Gravity|Alcohol_Content|Bitterness|Color|Ingredient_Ratio|Volume_Produced|Total_Sales|Quality_Score|Brewhouse_Efficiency|Loss_During_Brewing|Loss_During_Fermentation|Loss_During_Bottling_Kegging|\n",
      "+--------+---------+----------+---+--------+-----------------+-----------+--------+-------+---------------+----------+-----+----------------+---------------+-----------+-------------+--------------------+-------------------+------------------------+----------------------------+\n",
      "|       0|        0|         0|  0|       0|                0|          0|       0|      0|              0|         0|    0|               0|              0|          0|            0|                   0|                  0|                       0|                           0|\n",
      "+--------+---------+----------+---+--------+-----------------+-----------+--------+-------+---------------+----------+-----+----------------+---------------+-----------+-------------+--------------------+-------------------+------------------------+----------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Count missing values (nulls) for each column\n",
    "missing_values = df.select([count(when(col(c).isNull(), c)).alias(c) for c in df.columns])\n",
    "\n",
    "# Show the result\n",
    "missing_values.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ec54139a-0522-40d9-87dd-1ebae5f2f051",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned = df.dropna()  # Removes rows with any null value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e1a528e6-195b-44b0-8b9f-cf0af7406d0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows in dataset: 10000000\n"
     ]
    }
   ],
   "source": [
    "row_count = df_cleaned.count()\n",
    "print(f\"Total rows in dataset: {row_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "88b606bb-e37b-4ba0-92d7-6cf9f3b7b697",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---------+----------+---+--------+-----------------+-----------+--------+-------+---------------+----------+-----+----------------+---------------+-----------+-------------+--------------------+-------------------+------------------------+----------------------------+-----+\n",
      "|Batch_ID|Brew_Date|Beer_Style|SKU|Location|Fermentation_Time|Temperature|pH_Level|Gravity|Alcohol_Content|Bitterness|Color|Ingredient_Ratio|Volume_Produced|Total_Sales|Quality_Score|Brewhouse_Efficiency|Loss_During_Brewing|Loss_During_Fermentation|Loss_During_Bottling_Kegging|count|\n",
      "+--------+---------+----------+---+--------+-----------------+-----------+--------+-------+---------------+----------+-----+----------------+---------------+-----------+-------------+--------------------+-------------------+------------------------+----------------------------+-----+\n",
      "+--------+---------+----------+---+--------+-----------------+-----------+--------+-------+---------------+----------+-----+----------------+---------------+-----------+-------------+--------------------+-------------------+------------------------+----------------------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Show the duplicate records (based on all columns)\n",
    "duplicates_df = df.groupBy(df.columns).count().filter(\"count > 1\")\n",
    "duplicates_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce882dd0-750c-49b2-ace9-e06ca31d197f",
   "metadata": {},
   "source": [
    "2.3. Data Type Conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4e8f1f1e-69f2-40a7-8cc6-94fb8791826c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|Brew_Date |\n",
      "+----------+\n",
      "|2020-01-01|\n",
      "|2020-01-01|\n",
      "|2020-01-01|\n",
      "|2020-01-01|\n",
      "|2020-01-01|\n",
      "+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Convert 'Brew_Date' column to date only (removes time part)\n",
    "df = df.withColumn('Brew_Date', to_date(df['Brew_Date']))\n",
    "\n",
    "# Show the result to confirm the changes\n",
    "df.select('Brew_Date').show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1f140d88-3639-45e0-96fd-3dc3fc5d2c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned = df.withColumn('Fermentation_Time', df['Fermentation_Time'].cast('integer'))\n",
    "df_cleaned = df.withColumn('Brew_Date', df['Brew_Date'].cast('timestamp'))\n",
    "df_cleaned = df.withColumn('Temperature', df['Temperature'].cast('double'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0aea267-3fb9-4bde-867d-c8b7bc81ca61",
   "metadata": {},
   "source": [
    "2.4. Filtering Out Invalid Rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1dd393e2-e7ec-4c49-b1dc-01f72ab3f7b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out rows with invalid or impossible values\n",
    "df_cleaned = df_cleaned.filter((df_cleaned['Volume_Produced'] >= 0) & \n",
    "                               (df_cleaned['Temperature'] >= 0) & (df_cleaned['Temperature'] <= 100) & \n",
    "                               (df_cleaned['pH_Level'] >= 0) & (df_cleaned['pH_Level'] <= 14))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd75fac3-b16d-428c-b8f2-7297a783fe9e",
   "metadata": {},
   "source": [
    "1  Volume_Produced >= 0\n",
    "\n",
    "Reason: The volume of beer produced (Volume_Produced) cannot be negative because it represents the actual quantity of beer brewed. Negative values would indicate an impossible or erroneous record. So, filtering out values less than zero is essential to ensure data validity.\n",
    "\n",
    "2  Temperature >= 0 and Temperature <= 100\n",
    "\n",
    "Reason: Minimum Temperature (0°C): The minimum possible temperature for water or beer is 0°C (freezing point of water). Temperatures below this could indicate data errors, such as negative values that don’t make sense in the context of brewing processes.\n",
    "\n",
    "Maximum Temperature (100°C): 100°C is the boiling point of water at sea level. While brewing temperatures are typically below 100°C, extreme temperatures above 100°C would also be unusual. Therefore, this range is reasonable to filter out outliers or incorrect readings.\n",
    "Brewing Temperature: Generally, brewing temperatures range between 60°C to 75°C for most beer styles. While this range is broader (0–100°C) to account for potential outliers, it still removes obviously invalid or extreme data points.\n",
    "\n",
    "3 pH_Level >= 0 and pH_Level <= 14\n",
    "\n",
    "Reason: Minimum pH (0): The pH scale ranges from 0 to 14, with 0 being extremely acidic and 14 being extremely alkaline. A pH level below 0 is physically impossible for a solution, so filtering values below 0 is necessary to remove errors.\n",
    "\n",
    "Maximum pH (14): Similarly, a pH level above 14 is impossible in the context of beer brewing. Typical beer pH values range between 4.0 and 5.5, with some variation depending on the type of beer and fermentation conditions. Filtering values greater than 14 ensures that any erroneous or outlier values above the maximum pH scale are removed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d37c324-6952-4df3-ad14-612075bb9116",
   "metadata": {},
   "source": [
    "3 Data Analysis Using Spark SQL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "651f8f2f-a09d-4d58-a5c5-f8b99f1ec1d0",
   "metadata": {},
   "source": [
    "3.1.1) Aggregation: Calculate summary statistics (e.g., mean, median, standard deviation) of the numerical columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "68c94afb-b889-4773-b9fd-9b832126f88d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = df_cleaned\n",
    "df_final.createOrReplaceTempView(\"brewing_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fbe7da7a-b273-43c7-b7af-80716c513b86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+----------+----+------------+-----------------+------------------+------------------+------------------+-----------------+----------+-----+----------------+---------------+------------------+-----------------+--------------------+-------------------+------------------------+----------------------------+\n",
      "|Batch_ID| Brew_Date|Beer_Style| SKU|    Location|Fermentation_Time|       Temperature|          pH_Level|           Gravity|  Alcohol_Content|Bitterness|Color|Ingredient_Ratio|Volume_Produced|       Total_Sales|    Quality_Score|Brewhouse_Efficiency|Loss_During_Brewing|Loss_During_Fermentation|Loss_During_Bottling_Kegging|\n",
      "+--------+----------+----------+----+------------+-----------------+------------------+------------------+------------------+-----------------+----------+-----+----------------+---------------+------------------+-----------------+--------------------+-------------------+------------------------+----------------------------+\n",
      "| 7870796|2020-01-01|Wheat Beer|Kegs|  Whitefield|               16|24.204250857069873|5.2898454476095615|1.0395041267301979|5.370842159553436|        20|    5|     1:0.32:0.16|           4666|2664.7593448382822| 8.57701633109399|   89.19588216376087| 4.1049876591878345|      3.2354851724654683|           4.663204448186049|\n",
      "| 9810411|2020-01-01|      Sour|Kegs|  Whitefield|               13|18.086762947259544| 5.275643382756193|1.0598189516987164|5.096053082797625|        36|   14|     1:0.39:0.24|            832| 9758.801062471319|7.420540752553908|    72.4809153900275| 2.6765280953921122|      4.2461292104108574|            2.04435836917023|\n",
      "| 2623342|2020-01-01|Wheat Beer|Kegs| Malleswaram|               12|15.539332669116469|4.7780156232459765|1.0374757095487201|4.824737120959184|        30|   10|     1:0.35:0.16|           2115|11721.087016274963|8.451364886803127|   86.32214396020584|  3.299893625514981|       3.109440467362847|          3.0338798378762806|\n",
      "| 8114651|2020-01-01|       Ale|Kegs| Rajajinagar|               17| 16.41848910394318| 5.345260585546188|1.0524314251694946|5.509243080797997|        48|   18|     1:0.35:0.15|           3173|12050.177463190277|9.671859404043175|   83.09494037181545|  2.136055116262562|       4.634254174098425|          1.4898890677148424|\n",
      "| 4579587|2020-01-01|     Stout|Cans|Marathahalli|               18|19.144907654338517|  4.86185374113861|1.0542961149482333|5.133624684263243|        57|   13|     1:0.46:0.11|           4449|5515.0774647529615|7.895333676172065|   88.62583302052388|  4.491723843594972|      2.1833886016455497|          2.9906302188791485|\n",
      "+--------+----------+----------+----+------------+-----------------+------------------+------------------+------------------+-----------------+----------+-----+----------------+---------------+------------------+-----------------+--------------------+-------------------+------------------------+----------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Performing a SQL query to select all data from the brewing_data view\n",
    "cleaned_data_query = \"SELECT * FROM brewing_data\"\n",
    "final_df = spark.sql(cleaned_data_query)\n",
    "\n",
    "# Showing the first few rows of the cleaned data\n",
    "final_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0f5dcd32-e2b1-41a1-80aa-2c5e8ee5a2e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+---------------------+------------------+-----------------+------------------+-------------------+--------------+----------+-------------------+------------------+-----------------+------------------------+-----------------------+----------------------------+--------------------------------+---------------+------------------------+------------------+-----------------+------------------+----------------------+-----------------+------------+----------------------+------------------+--------------------+---------------------------+--------------------------+-------------------------------+-----------------------------------+------------------+------------------------+------------------+-------------------+--------------------+----------------------+------------------+-----------------+----------------------+------------------+--------------------+---------------------------+--------------------------+-------------------------------+-----------------------------------+\n",
      "|avg_Batch_ID|avg_Fermentation_Time|avg_Temperature   |avg_pH_Level     |avg_Gravity       |avg_Alcohol_Content|avg_Bitterness|avg_Color |avg_Volume_Produced|avg_Total_Sales   |avg_Quality_Score|avg_Brewhouse_Efficiency|avg_Loss_During_Brewing|avg_Loss_During_Fermentation|avg_Loss_During_Bottling_Kegging|median_Batch_ID|median_Fermentation_Time|median_Temperature|median_pH_Level  |median_Gravity    |median_Alcohol_Content|median_Bitterness|median_Color|median_Volume_Produced|median_Total_Sales|median_Quality_Score|median_Brewhouse_Efficiency|median_Loss_During_Brewing|median_Loss_During_Fermentation|median_Loss_During_Bottling_Kegging|stddev_Batch_ID   |stddev_Fermentation_Time|stddev_Temperature|stddev_pH_Level    |stddev_Gravity      |stddev_Alcohol_Content|stddev_Bitterness |stddev_Color     |stddev_Volume_Produced|stddev_Total_Sales|stddev_Quality_Score|stddev_Brewhouse_Efficiency|stddev_Loss_During_Brewing|stddev_Loss_During_Fermentation|stddev_Loss_During_Bottling_Kegging|\n",
      "+------------+---------------------+------------------+-----------------+------------------+-------------------+--------------+----------+-------------------+------------------+-----------------+------------------------+-----------------------+----------------------------+--------------------------------+---------------+------------------------+------------------+-----------------+------------------+----------------------+-----------------+------------+----------------------+------------------+--------------------+---------------------------+--------------------------+-------------------------------+-----------------------------------+------------------+------------------------+------------------+-------------------+--------------------+----------------------+------------------+-----------------+----------------------+------------------+--------------------+---------------------------+--------------------------+-------------------------------+-----------------------------------+\n",
      "|4999999.5   |14.500898            |19.999898511018827|4.999940543893489|1.0550028700788692|5.249709006579308  |39.4961996    |11.9993459|2749.0309594       |10497.785343940232|7.999825148192516|80.00091934182497       |3.000081497042524      |3.000002413212497           |3.0001587106749747              |4999672        |15                      |19.999639059280874|4.999862833836904|1.0550036147017112|5.249840017352465     |39               |12          |2749                  |10495.819326532543|7.999859661747688   |80.00193042786057          |2.999649890349522         |2.999689053088824              |3.000579322020188                  |2886751.4902856858|2.872006096518228       |2.8870297120328576|0.28863762894103545|0.014434649211836703|0.43296144791729213   |11.545572488490313|4.321170228005893|1299.078133259011     |5485.995544804044 |1.1546793056214646  |5.7749295785811645         |1.1547483756083143        |1.1548266863212513             |1.1547186092997934                 |\n",
      "+------------+---------------------+------------------+-----------------+------------------+-------------------+--------------+----------+-------------------+------------------+-----------------+------------------------+-----------------------+----------------------------+--------------------------------+---------------+------------------------+------------------+-----------------+------------------+----------------------+-----------------+------------+----------------------+------------------+--------------------+---------------------------+--------------------------+-------------------------------+-----------------------------------+------------------+------------------------+------------------+-------------------+--------------------+----------------------+------------------+-----------------+----------------------+------------------+--------------------+---------------------------+--------------------------+-------------------------------+-----------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Identifying numeric columns in the cleaned data\n",
    "numeric_columns = [field.name for field in final_df.schema.fields \n",
    "                   if isinstance(field.dataType, (FloatType, DoubleType, IntegerType))]\n",
    "\n",
    "# Generating SQL queries for summary statistics (mean, median, standard deviation)\n",
    "summary_query = f\"\"\"\n",
    "SELECT \n",
    "    {', '.join([f'AVG({col}) AS avg_{col}' for col in numeric_columns])},\n",
    "    {', '.join([f'PERCENTILE_APPROX({col}, 0.5) AS median_{col}' for col in numeric_columns])},\n",
    "    {', '.join([f'STDDEV({col}) AS stddev_{col}' for col in numeric_columns])}\n",
    "FROM brewing_data\n",
    "\"\"\"\n",
    "\n",
    "# Executing the SQL query to calculate summary statistics\n",
    "summary_df = spark.sql(summary_query)\n",
    "\n",
    "# Showing the summary statistics DataFrame\n",
    "summary_df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e018d398-5d6c-4f81-bf69-9d521ce247b4",
   "metadata": {},
   "source": [
    "3.1.2) Grouping and Filtering: Group data by specific categories and calculate aggregations for each group. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d3b3054-c1e7-4c72-a2c2-d00a58d50604",
   "metadata": {},
   "source": [
    "Highest Total_Sales per Brew_Date and Beer_Style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7ea6484d-1dd4-41b7-ac9f-f4377ca6e4f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+-------------------+\n",
      "|Brew_Date |Beer_Style|Highest_Total_Sales|\n",
      "+----------+----------+-------------------+\n",
      "|2023-12-31|Sour      |19999.957753273946 |\n",
      "|2023-12-31|Porter    |19998.713582154644 |\n",
      "|2023-12-31|Pilsner   |19998.166499284678 |\n",
      "|2023-12-31|Stout     |19991.554562673293 |\n",
      "|2023-12-31|Wheat Beer|19988.27588543136  |\n",
      "|2023-12-31|Lager     |19980.77426642725  |\n",
      "|2023-12-31|Ale       |19965.82561229111  |\n",
      "|2023-12-31|IPA       |19956.92365618578  |\n",
      "|2023-12-30|Ale       |19996.39620222792  |\n",
      "|2023-12-30|IPA       |19992.75046454753  |\n",
      "+----------+----------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# SQL query to find the highest Total_Sales per Brew_Date and Beer_Style, ordered by date\n",
    "aggregation_query = \"\"\"\n",
    "SELECT \n",
    "    Brew_Date,\n",
    "    Beer_Style,\n",
    "    MAX(Total_Sales) AS Highest_Total_Sales\n",
    "FROM brewing_data\n",
    "GROUP BY Brew_Date, Beer_Style\n",
    "ORDER BY Brew_Date DESC, Highest_Total_Sales DESC\n",
    "LIMIT 10\n",
    "\"\"\"\n",
    "\n",
    "# Execute the query\n",
    "result_df = spark.sql(aggregation_query)\n",
    "\n",
    "# Show the results\n",
    "result_df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7db9f61c-3ee3-4077-bb8d-db44b6c667ce",
   "metadata": {},
   "source": [
    "Highest Quality_Score per Brew_Date and Beer_Style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "40c1c354-acfd-45e1-9705-fd9d5a4d7c96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+---------------------+\n",
      "|Brew_Date |Beer_Style|Highest_Quality_Score|\n",
      "+----------+----------+---------------------+\n",
      "|2023-12-31|Sour      |9.999161865781595    |\n",
      "|2023-12-31|Pilsner   |9.998151783823628    |\n",
      "|2023-12-31|Ale       |9.9972227757805      |\n",
      "|2023-12-31|Porter    |9.99697217893943     |\n",
      "|2023-12-31|IPA       |9.996293456793538    |\n",
      "|2023-12-31|Wheat Beer|9.994572202670671    |\n",
      "|2023-12-31|Stout     |9.990243632639132    |\n",
      "|2023-12-31|Lager     |9.984752221429648    |\n",
      "|2023-12-30|Ale       |9.999722934959543    |\n",
      "|2023-12-30|IPA       |9.999592070600983    |\n",
      "+----------+----------+---------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# SQL query to find the highest Quality_Score per Brew_Date and Beer_Style, ordered by date\n",
    "aggregation_query = \"\"\"\n",
    "SELECT \n",
    "    Brew_Date,\n",
    "    Beer_Style,\n",
    "    MAX(Quality_Score) AS Highest_Quality_Score\n",
    "FROM brewing_data\n",
    "GROUP BY Brew_Date, Beer_Style\n",
    "ORDER BY Brew_Date DESC, Highest_Quality_Score DESC\n",
    "LIMIT 10\n",
    "\"\"\"\n",
    "\n",
    "# Execute the query\n",
    "result_df = spark.sql(aggregation_query)\n",
    "\n",
    "# Show the results\n",
    "result_df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90da86cb-6fae-4138-b414-37e867c817fb",
   "metadata": {},
   "source": [
    "Highest Volume_Produced per Brew_Date and Beer_Style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fcae1123-aed7-4c32-bc11-816440e43db6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+-----------------------+\n",
      "|Brew_Date |Beer_Style|Highest_Volume_Produced|\n",
      "+----------+----------+-----------------------+\n",
      "|2023-12-31|Ale       |4999                   |\n",
      "|2023-12-31|Pilsner   |4999                   |\n",
      "|2023-12-31|Stout     |4998                   |\n",
      "|2023-12-31|IPA       |4996                   |\n",
      "|2023-12-31|Sour      |4996                   |\n",
      "|2023-12-31|Lager     |4993                   |\n",
      "|2023-12-31|Wheat Beer|4990                   |\n",
      "|2023-12-31|Porter    |4986                   |\n",
      "|2023-12-30|Wheat Beer|4999                   |\n",
      "|2023-12-30|Lager     |4997                   |\n",
      "+----------+----------+-----------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# SQL query to find the highest Volume_Produced per Brew_Date and Beer_Style, ordered by date\n",
    "aggregation_query = \"\"\"\n",
    "SELECT \n",
    "    Brew_Date,\n",
    "    Beer_Style,\n",
    "    MAX(Volume_Produced) AS Highest_Volume_Produced\n",
    "FROM brewing_data\n",
    "GROUP BY Brew_Date, Beer_Style\n",
    "ORDER BY Brew_Date DESC, Highest_Volume_Produced DESC\n",
    "LIMIT 10\n",
    "\"\"\"\n",
    "\n",
    "# Execute the query\n",
    "result_df = spark.sql(aggregation_query)\n",
    "\n",
    "# Show the results\n",
    "result_df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b12c19f-9d0d-4788-a516-5461ca91b471",
   "metadata": {},
   "source": [
    "3.1.3) Joins: If applicable, perform a join between two tables\n",
    "\n",
    "Are not applicable for our dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e23df966-61d9-4c0a-8ae1-cba0f9ce8ab7",
   "metadata": {},
   "source": [
    "3.1.4) Time-based analysis: If your dataset contains a timestamp column, analyze trends over time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b30381bc-5e47-425a-9123-31142feea064",
   "metadata": {},
   "source": [
    "SQL query for number of batches and total sales per Brew_Date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5b363f19-60e1-46be-9f36-a71bda77a5d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------------+-------------------+\n",
      "|Brew_Date |Number_of_Batches|Total_Sales_Per_Day|\n",
      "+----------+-----------------+-------------------+\n",
      "|2023-12-31|6951             |7.402164022621739E7|\n",
      "|2023-12-30|6875             |7.277619057643037E7|\n",
      "|2023-12-29|6801             |7.101619643852998E7|\n",
      "|2023-12-28|6853             |7.161239863457432E7|\n",
      "|2023-12-27|6823             |7.105070785238072E7|\n",
      "|2023-12-26|6778             |7.173696041901506E7|\n",
      "|2023-12-25|6975             |7.328681953301111E7|\n",
      "|2023-12-24|6945             |7.398418149452E7   |\n",
      "|2023-12-23|6809             |7.171651056100419E7|\n",
      "|2023-12-22|6787             |7.072098217357387E7|\n",
      "+----------+-----------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# SQL query to find the number of batches and total sales per Brew_Date\n",
    "time_based_query = \"\"\"\n",
    "SELECT \n",
    "    Brew_Date,\n",
    "    COUNT(Batch_ID) AS Number_of_Batches,\n",
    "    SUM(Total_Sales) AS Total_Sales_Per_Day\n",
    "FROM brewing_data\n",
    "GROUP BY Brew_Date\n",
    "ORDER BY Brew_Date DESC\n",
    "LIMIT 10\n",
    "\"\"\"\n",
    "\n",
    "# Execute the query\n",
    "result_time_based_df = spark.sql(time_based_query)\n",
    "\n",
    "# Show the results\n",
    "result_time_based_df.show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16c5407a-9daf-41fd-a596-0c9d92a00777",
   "metadata": {},
   "source": [
    "SQL Query for Average Quality Score and Alcohol Content per Brew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "91688835-edf5-461e-b236-898f67488e89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------------------+-----------------------+\n",
      "|Brew_Date |Average_Quality_Score|Average_Alcohol_Content|\n",
      "+----------+---------------------+-----------------------+\n",
      "|2023-12-31|7.972432599968671    |5.247159001244369      |\n",
      "|2023-12-30|7.972838103070529    |5.246944176486663      |\n",
      "|2023-12-29|8.000243096635971    |5.2470258847132065     |\n",
      "|2023-12-28|8.01174732752383     |5.2542033652894995     |\n",
      "|2023-12-27|7.994104801119074    |5.239622772825028      |\n",
      "|2023-12-26|7.998919681970579    |5.245127095144804      |\n",
      "|2023-12-25|8.01056465475819     |5.244991263699129      |\n",
      "|2023-12-24|7.993671636436315    |5.253078226738263      |\n",
      "|2023-12-23|7.992270025832132    |5.248499193071808      |\n",
      "|2023-12-22|7.99786223144857     |5.257680459953336      |\n",
      "+----------+---------------------+-----------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# SQL query to find the average Quality Score and Alcohol Content per Brew_Date\n",
    "average_metrics_query = \"\"\"\n",
    "SELECT \n",
    "    Brew_Date,\n",
    "    AVG(Quality_Score) AS Average_Quality_Score,\n",
    "    AVG(Alcohol_Content) AS Average_Alcohol_Content\n",
    "FROM brewing_data\n",
    "GROUP BY Brew_Date\n",
    "ORDER BY Brew_Date DESC\n",
    "LIMIT 10\n",
    "\"\"\"\n",
    "\n",
    "# Execute the query\n",
    "result_average_metrics_df = spark.sql(average_metrics_query)\n",
    "\n",
    "# Show the results\n",
    "result_average_metrics_df.show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeb04c3d-2d4a-4f78-b270-dad299026fd7",
   "metadata": {},
   "source": [
    "SQL Query for Beer Style Count per Brew Date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "87591568-ff8f-439c-b6da-a8cd0a65da80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+----------------+\n",
      "|Brew_Date |Beer_Style|Beer_Style_Count|\n",
      "+----------+----------+----------------+\n",
      "|2023-12-31|Lager     |892             |\n",
      "|2023-12-31|Ale       |879             |\n",
      "|2023-12-31|Wheat Beer|877             |\n",
      "|2023-12-31|IPA       |876             |\n",
      "|2023-12-31|Stout     |876             |\n",
      "|2023-12-31|Pilsner   |864             |\n",
      "|2023-12-31|Sour      |853             |\n",
      "|2023-12-31|Porter    |834             |\n",
      "|2023-12-30|Sour      |905             |\n",
      "|2023-12-30|Stout     |901             |\n",
      "+----------+----------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# SQL query to count the number of each Beer Style produced per Brew_Date\n",
    "beer_style_count_query = \"\"\"\n",
    "SELECT \n",
    "    Brew_Date,\n",
    "    Beer_Style,\n",
    "    COUNT(*) AS Beer_Style_Count\n",
    "FROM brewing_data\n",
    "GROUP BY Brew_Date, Beer_Style\n",
    "ORDER BY Brew_Date DESC, Beer_Style_Count DESC\n",
    "LIMIT 10\n",
    "\"\"\"\n",
    "\n",
    "# Execute the query\n",
    "result_beer_style_count_df = spark.sql(beer_style_count_query)\n",
    "\n",
    "# Show the results\n",
    "result_beer_style_count_df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03ff03c9-cb88-422f-9f5e-4cfe550a54bd",
   "metadata": {},
   "source": [
    "Insights:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "791f8a30-5bca-453f-a098-7ce168c8c697",
   "metadata": {},
   "source": [
    "1 Highest Total Sales\n",
    "   \n",
    "Top Performers: On 2023-12-31, Sour beer led in total sales, followed closely by Porter, Pilsner, and Stout.\n",
    "Beer Style Performance: Most beer styles show high total sales on 2023-12-31, indicating that this was likely a peak day for sales overall.\n",
    "Sales Trend: The sales on 2023-12-30 were slightly lower, with Ale and IPA performing well, although sales for other styles were still significant.\n",
    "\n",
    "2 Highest Quality Score\n",
    "\n",
    "Top Performers: Sour beer had the highest quality score on 2023-12-31, followed by Pilsner and Ale. This suggests that consumers rated these beer styles very highly.\n",
    "Quality Consistency: Quality scores across all beer styles are consistently high, particularly on 2023-12-30, where the Ale beer style achieved almost a perfect score.\n",
    "\n",
    "3 Highest Volume Produced\n",
    "\n",
    "Volume Consistency: Ale and Pilsner beer styles led in volume produced on 2023-12-31, both reaching 4999 units, indicating significant production for these styles.\n",
    "Production Trends: Stout and IPA also had high production numbers, but the volume produced slightly dropped for some styles like Porter.\n",
    "\n",
    "4 Number of Batches and Sales per Day\n",
    "\n",
    "Batches and Sales Volume: 2023-12-31 recorded the highest number of batches (6951) and highest sales per day (around 74 million), suggesting that it was a high-volume production day.\n",
    "Sales Correlation: The total sales per day shows fluctuations but remains high on 2023-12-31. The data indicates a very active production and sales environment, possibly around the holiday season.\n",
    "\n",
    "5 Average Quality Score and Alcohol Content\n",
    "\n",
    "Consistency in Quality Score: The average quality scores remain high across all the days, with a slight dip on 2023-12-31.\n",
    "Alcohol Content: Average alcohol content remains relatively stable, with 2023-12-31 having an average of about 5.25%. This suggests no major variations in the types of beer produced during this period.\n",
    "\n",
    "6 Beer Style Count\n",
    "\n",
    "Lager and Ale Dominance: Lager and Ale were the most produced and sold beers on 2023-12-31, with Lager topping the list at 892 batches.\n",
    "Beer Style Spread: The number of batches for Sour and Porter were slightly lower compared to others, indicating less production or popularity during this period.\n",
    "\n",
    "Key Observations:\n",
    "\n",
    "Sales and Production Peaks: The peak sales figures on 2023-12-31 align with increased production and higher quality scores for various beer styles, especially Sour and Pilsner.\n",
    "\n",
    "Quality and Volume Correlation: Beer styles with high total sales on 2023-12-31 (like Sour and Pilsner) also had some of the highest quality scores, which indicates a strong positive correlation between quality and sales.\n",
    "\n",
    "Beer Preferences: Ale and IPA are the more commonly produced beer styles, while Sour and Porter might have smaller but more targeted batches, with high-quality ratings."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6b7e268-be0c-4dd0-9fd2-87bc253a772e",
   "metadata": {},
   "source": [
    "4 Machine Learning Model (Regression/Classification)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d02686c-32fe-4d75-af37-9301bffc7a2d",
   "metadata": {},
   "source": [
    "4.1 Choose the appropriate ML problem based on the dataset:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b269fe9-6add-4fb5-ae77-7442f15d5461",
   "metadata": {},
   "source": [
    "Justification for Regression Model Selection\n",
    "I'm selecting a regression model to predict Total Sales because:\n",
    "\n",
    "Nature of the Target Variable (Total Sales):\n",
    "\n",
    "Total Sales is a continuous numeric value, making it a natural fit for regression. The goal is to predict a specific value that can take on any numeric value within a range, which is a hallmark of regression problems.\n",
    "\n",
    "The primary objective is to predict Total Sales based on various influencing factors such as Beer Style, Number of Batches, and Average Quality Score. This prediction can provide valuable insights for forecasting, budget allocation, and sales strategy, making it a key decision-making tool.\n",
    "Using regression allows us to generate continuous predictions for total sales, which can be leveraged to adjust strategies in real-time based on predicted values.\n",
    "\n",
    "Predictive Power:\n",
    "\n",
    "Since Total Sales is directly influenced by multiple continuous features (e.g., Beer Style Count, Average Alcohol Content, Brew_Date, etc.), regression models are well-suited to capture these relationships and provide accurate numerical predictions. This can help in resource planning, inventory management, and understanding demand trends.\n",
    "Given this, the regression approach is optimal for our dataset, where we want to predict the Total Sales based on a variety of features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e567082-2842-4055-bae4-9f1a679ad303",
   "metadata": {},
   "source": [
    "Model: Random Forest Regressor\n",
    "\n",
    "Random Forest Regressor for the following reasons:\n",
    "\n",
    "Handles Non-linearity: The relationships between Total Sales and features like Beer Style Count, Average Quality Score, and Number of Batches may be complex and non-linear. Random Forest can capture these complex relationships, unlike linear models.\n",
    "\n",
    "Robustness: It is less prone to overfitting compared to a single decision tree, as it uses an ensemble of trees. This makes it a more robust choice when dealing with real-world, noisy data.\n",
    "\n",
    "Feature Importance: Random Forest provides insights into feature importance, which can help identify which features contribute most to predicting Total Sales, aiding in business decisions.\n",
    "\n",
    "Accuracy: It generally provides better predictive accuracy compared to simpler models like linear regression, especially for more complex problems with multiple interacting features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a956a2d0-42e3-42f8-8e4c-8be49146ec08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pyspark.sql.dataframe.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "print(type(df_cleaned))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "884c9e9b-2f0a-48dc-a94e-e2bfade7bd35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+----------+----+------------+-----------------+------------------+------------------+------------------+-----------------+----------+-----+----------------+---------------+------------------+-----------------+--------------------+-------------------+------------------------+----------------------------+\n",
      "|Batch_ID| Brew_Date|Beer_Style| SKU|    Location|Fermentation_Time|       Temperature|          pH_Level|           Gravity|  Alcohol_Content|Bitterness|Color|Ingredient_Ratio|Volume_Produced|       Total_Sales|    Quality_Score|Brewhouse_Efficiency|Loss_During_Brewing|Loss_During_Fermentation|Loss_During_Bottling_Kegging|\n",
      "+--------+----------+----------+----+------------+-----------------+------------------+------------------+------------------+-----------------+----------+-----+----------------+---------------+------------------+-----------------+--------------------+-------------------+------------------------+----------------------------+\n",
      "| 7870796|2020-01-01|Wheat Beer|Kegs|  Whitefield|               16|24.204250857069873|5.2898454476095615|1.0395041267301979|5.370842159553436|        20|    5|     1:0.32:0.16|           4666|2664.7593448382822| 8.57701633109399|   89.19588216376087| 4.1049876591878345|      3.2354851724654683|           4.663204448186049|\n",
      "| 9810411|2020-01-01|      Sour|Kegs|  Whitefield|               13|18.086762947259544| 5.275643382756193|1.0598189516987164|5.096053082797625|        36|   14|     1:0.39:0.24|            832| 9758.801062471319|7.420540752553908|    72.4809153900275| 2.6765280953921122|      4.2461292104108574|            2.04435836917023|\n",
      "| 2623342|2020-01-01|Wheat Beer|Kegs| Malleswaram|               12|15.539332669116469|4.7780156232459765|1.0374757095487201|4.824737120959184|        30|   10|     1:0.35:0.16|           2115|11721.087016274963|8.451364886803127|   86.32214396020584|  3.299893625514981|       3.109440467362847|          3.0338798378762806|\n",
      "| 8114651|2020-01-01|       Ale|Kegs| Rajajinagar|               17| 16.41848910394318| 5.345260585546188|1.0524314251694946|5.509243080797997|        48|   18|     1:0.35:0.15|           3173|12050.177463190277|9.671859404043175|   83.09494037181545|  2.136055116262562|       4.634254174098425|          1.4898890677148424|\n",
      "| 4579587|2020-01-01|     Stout|Cans|Marathahalli|               18|19.144907654338517|  4.86185374113861|1.0542961149482333|5.133624684263243|        57|   13|     1:0.46:0.11|           4449|5515.0774647529615|7.895333676172065|   88.62583302052388|  4.491723843594972|      2.1833886016455497|          2.9906302188791485|\n",
      "+--------+----------+----------+----+------------+-----------------+------------------+------------------+------------------+-----------------+----------+-----+----------------+---------------+------------------+-----------------+--------------------+-------------------+------------------------+----------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_cleaned.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffe86592-62ea-4e52-a1a9-dab03e67d419",
   "metadata": {},
   "source": [
    "Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "dcfb30bf-2608-44bd-8f56-77c9704e5a56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Batch_ID',\n",
       " 'Brew_Date',\n",
       " 'Beer_Style',\n",
       " 'SKU',\n",
       " 'Location',\n",
       " 'Fermentation_Time',\n",
       " 'Temperature',\n",
       " 'pH_Level',\n",
       " 'Gravity',\n",
       " 'Alcohol_Content',\n",
       " 'Bitterness',\n",
       " 'Color',\n",
       " 'Ingredient_Ratio',\n",
       " 'Volume_Produced',\n",
       " 'Total_Sales',\n",
       " 'Quality_Score',\n",
       " 'Brewhouse_Efficiency',\n",
       " 'Loss_During_Brewing',\n",
       " 'Loss_During_Fermentation',\n",
       " 'Loss_During_Bottling_Kegging']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cleaned.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0ab29d2e-a88b-442f-862e-fe59d20684e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation between Batch_ID and Total_Sales: -0.00015943984849964196\n",
      "Correlation between Fermentation_Time and Total_Sales: 0.0001702529220165709\n",
      "Correlation between Temperature and Total_Sales: 4.812389524730911e-05\n",
      "Correlation between pH_Level and Total_Sales: -4.858993765998827e-05\n",
      "Correlation between Gravity and Total_Sales: 0.000514309198615154\n",
      "Correlation between Alcohol_Content and Total_Sales: 0.0005225099074256979\n",
      "Correlation between Bitterness and Total_Sales: -0.00015433550969259514\n",
      "Correlation between Color and Total_Sales: 0.00014694286695053862\n",
      "Correlation between Volume_Produced and Total_Sales: 4.539233729138603e-05\n",
      "Correlation between Quality_Score and Total_Sales: 0.000516940642588387\n",
      "Correlation between Brewhouse_Efficiency and Total_Sales: 0.00018469634422112627\n",
      "Correlation between Loss_During_Brewing and Total_Sales: 0.00016438722970381857\n",
      "Correlation between Loss_During_Fermentation and Total_Sales: -0.0003096972210355463\n",
      "Correlation between Loss_During_Bottling_Kegging and Total_Sales: 0.00030911885067258504\n"
     ]
    }
   ],
   "source": [
    "# Filter out non-numeric columns\n",
    "numeric_cols = [col for col, dtype in df_cleaned.dtypes if dtype in ('int', 'double')]\n",
    "\n",
    "# Select only the numeric columns\n",
    "numeric_df = df_cleaned.select(*numeric_cols)\n",
    "\n",
    "# Calculate correlation with 'Total_Sales' for each numeric column\n",
    "for col in numeric_df.columns:\n",
    "    if col != 'Total_Sales':  # Skip correlation with itself\n",
    "        corr_val = numeric_df.stat.corr(col, 'Total_Sales')\n",
    "        print(f\"Correlation between {col} and Total_Sales: {corr_val}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fa2c492e-357d-412a-9ab4-20dd70177941",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "# Calculate Brew_Year_Efficiency\n",
    "df_cleaned = df_cleaned.withColumn(\n",
    "    \"Brew_Year_Efficiency\", col(\"Volume_Produced\") / col(\"Brewhouse_Efficiency\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "be66a098-391f-49d8-8463-2d6d03d7033d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Number_of_Batches as the count of distinct Batch_ID per SKU\n",
    "batch_counts = df_cleaned.groupBy(\"SKU\").agg({\"Batch_ID\": \"count\"}).withColumnRenamed(\"count(Batch_ID)\", \"Number_of_Batches\")\n",
    "\n",
    "# Join the batch counts back to the original DataFrame\n",
    "df_cleaned = df_cleaned.join(batch_counts, on=\"SKU\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ef151af2-57d2-472c-8cb7-e34eb2c5ac67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Volume_per_Batch\n",
    "df_cleaned = df_cleaned.withColumn(\n",
    "    \"Volume_per_Batch\", col(\"Volume_Produced\") / col(\"Number_of_Batches\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b52e3e73-1552-4c55-a900-0f9bad38e520",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the year from the Brew_Date column and create a new column 'Brew_Year'\n",
    "df_cleaned = df_cleaned.withColumn(\"Brew_Year\", year(\"Brew_Date\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "999a5ef9-cfcc-40dc-858e-4f3460b5a2b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------------+--------------------+--------------------+-----------------+--------------------+\n",
      "|Brew_Year|Volume_Produced|Brewhouse_Efficiency|Brew_Year_Efficiency|Number_of_Batches|    Volume_per_Batch|\n",
      "+---------+---------------+--------------------+--------------------+-----------------+--------------------+\n",
      "|     2020|           4449|   88.62583302052388|   50.19981024008773|          2498777|0.001780471006416...|\n",
      "|     2020|           4666|   89.19588216376087|   52.31183196813244|          2498753|0.001867331424914...|\n",
      "|     2020|            832|    72.4809153900275|  11.478883724397237|          2498753|3.329660834824410...|\n",
      "|     2020|           2115|   86.32214396020584|  24.501245022076915|          2498753|8.464221953910611E-4|\n",
      "|     2020|           3173|   83.09494037181545|   38.18523710110554|          2498753|0.001269833392896...|\n",
      "+---------+---------------+--------------------+--------------------+-----------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_cleaned.select(\"Brew_Year\", \"Volume_Produced\", \"Brewhouse_Efficiency\", \"Brew_Year_Efficiency\", \"Number_of_Batches\", \"Volume_per_Batch\").show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a6a14756-a803-47dd-98c0-2a6c86bd21b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation between Brew_Year and Total_Sales: -0.0006929445859795882\n",
      "Correlation between Volume_Produced and Total_Sales: 4.539233729138603e-05\n",
      "Correlation between Brewhouse_Efficiency and Total_Sales: 0.00018469634422112627\n",
      "Correlation between Brew_Year_Efficiency and Total_Sales: 4.126405403179541e-06\n",
      "Correlation between Number_of_Batches and Total_Sales: 8.185164315756284e-05\n",
      "Correlation between Volume_per_Batch and Total_Sales: 4.522094621693578e-05\n",
      "Correlation between Total_Sales and Total_Sales: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Recalculate the correlation matrix including the new columns\n",
    "columns_to_check = [\"Brew_Year\", \"Volume_Produced\", \"Brewhouse_Efficiency\", \"Brew_Year_Efficiency\", \n",
    "                    \"Number_of_Batches\", \"Volume_per_Batch\", \"Total_Sales\"]\n",
    "\n",
    "# Loop over the columns and calculate the correlation with Total_Sales\n",
    "for col_name in columns_to_check:\n",
    "    corr_val = df_cleaned.stat.corr(col_name, 'Total_Sales')\n",
    "    print(f\"Correlation between {col_name} and Total_Sales: {corr_val}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b44741c9-a1a4-4573-be1d-b04f8b19adf6",
   "metadata": {},
   "source": [
    "Identify Key Predictors: Understanding which features have a high correlation with Total_Sales helps us identify which variables might be more influential in predicting Total_Sales. Highly correlated features are usually strong candidates for inclusion in a predictive model.\n",
    "\n",
    "Feature Selection: If certain features are highly correlated with the target, they may be more valuable for model training, while features with little to no correlation might be less useful. This step helps us prioritize which columns to keep as predictors and which to potentially exclude.\n",
    "\n",
    "New Features Assessment: Since some new columns (like Brew_Year_Efficiency and Volume_per_Batch) were recently added, this process allows us to assess whether these new features provide additional explanatory power for predicting Total_Sales.\n",
    "\n",
    "Insight into Relationships: The correlation matrix gives insights into relationships between variables in the data. Positive correlations suggest that as one variable increases, so does Total_Sales, while negative correlations suggest the opposite.\n",
    "\n",
    "By recalculating the correlation matrix with the new columns, we refine our understanding of the data and its key drivers, which informs subsequent model-building steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e3dbfb0e-6564-4fc2-bf35-656e87d25a00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------------+--------------------+-----------------+------------------+\n",
      "|Brew_Year|Volume_Produced|Brewhouse_Efficiency|Number_of_Batches|       Total_Sales|\n",
      "+---------+---------------+--------------------+-----------------+------------------+\n",
      "|     2020|           4449|   88.62583302052388|          2498777|5515.0774647529615|\n",
      "|     2020|           4666|   89.19588216376087|          2498753|2664.7593448382822|\n",
      "|     2020|            832|    72.4809153900275|          2498753| 9758.801062471319|\n",
      "|     2020|           2115|   86.32214396020584|          2498753|11721.087016274963|\n",
      "|     2020|           3173|   83.09494037181545|          2498753|12050.177463190277|\n",
      "+---------+---------------+--------------------+-----------------+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create a new DataFrame with the selected columns\n",
    "df_selected = df_cleaned.select(\"Brew_Year\", \"Volume_Produced\", \"Brewhouse_Efficiency\", \"Number_of_Batches\", \"Total_Sales\")\n",
    "\n",
    "# Show the first few rows to verify\n",
    "df_selected.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bf97940-4d26-4fae-a18d-ec4fec55855c",
   "metadata": {},
   "source": [
    "Feature Selection:\n",
    "\n",
    "I first performed a correlation analysis between the target variable Total_Sales and other columns in the dataset to identify potential relationships.\n",
    "Based on the correlation results, I identified the columns with the strongest relationships with Total_Sales. The columns that were kept for further analysis were:\n",
    "\n",
    "Volume_Produced: Represents the total volume of beer produced, which likely influences total sales.\n",
    "\n",
    "Brewhouse_Efficiency: Indicates how efficiently the brewhouse operates, which can impact production output and sales.\n",
    "\n",
    "Number_of_Batches: Represents the number of production batches, which may correlate with the total volume produced and ultimately affect sales.\n",
    "\n",
    "Columns like Brew_Year_Efficiency, Brew_Year, and Volume_per_Batch were not retained due to their weaker correlations with Total_Sales.\n",
    "\n",
    "New DataFrame Creation:\n",
    "\n",
    "After feature selection, I created a new DataFrame (df_selected) containing only the relevant columns: Volume_Produced, Brewhouse_Efficiency, Number_of_Batches, and Total_Sales.\n",
    "\n",
    "This new DataFrame serves as the clean, simplified dataset that can be used for further modeling and analysis.\n",
    "\n",
    "The goal of this step was to reduce dimensionality and retain only the most influential features for predicting Total_Sales.\n",
    "\n",
    "By removing weaker or redundant features, we improve the model's performance and efficiency, ensuring that the machine learning model can focus on the key factors driving sales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0e2f1f1c-ba33-41a9-8d26-61c49cc47afd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+--------------------+-----------------+------------------+---------------+\n",
      "|Volume_Produced|Brewhouse_Efficiency|Number_of_Batches|       Total_Sales|Brew_Year_Index|\n",
      "+---------------+--------------------+-----------------+------------------+---------------+\n",
      "|            593|   85.73496269913532|          2500873|14362.653665879505|            0.0|\n",
      "|           4894|   85.26361099177572|          2500873|11852.097970324789|            0.0|\n",
      "|           4486|   89.49078286225225|          2500873|1665.1818593163712|            0.0|\n",
      "|           3809|   88.37087230231108|          2500873| 5925.879914754564|            0.0|\n",
      "|           4727|   70.66652472059178|          2500873|19228.362127803455|            0.0|\n",
      "+---------------+--------------------+-----------------+------------------+---------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import StringIndexer\n",
    "\n",
    "# Step 1: Use StringIndexer to convert Brew_Year to a numeric index\n",
    "indexer = StringIndexer(inputCol=\"Brew_Year\", outputCol=\"Brew_Year_Index\")\n",
    "df_selected = indexer.fit(df_selected).transform(df_selected)\n",
    "\n",
    "# Step 2: Drop the original Brew_Year column\n",
    "df_selected = df_selected.drop(\"Brew_Year\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f95f4beb-0831-4130-aa0b-2ddf36903ff7",
   "metadata": {},
   "source": [
    "We applied a StringIndexer to the Brew_Year column, creating a new column, Brew_Year_Index, with numerical values instead of categorical text values.\n",
    "\n",
    "Why We Did It:\n",
    "\n",
    "Machine Learning Compatibility: Most machine learning algorithms cannot directly process categorical string data. They require features to be in numerical form. StringIndexer converts each unique text category into a unique numeric index.\n",
    "Encoding Categories: StringIndexer assigns a numerical index to each unique value in Brew_Year. For example, if Brew_Year contains values like \"2020\", \"2021\", and \"2022\", each one will be mapped to a distinct number (like 0, 1, 2, etc.). This maintains the categorical information in a machine-readable form without implying any specific order among years.\n",
    "\n",
    "Facilitates Vectorization: This numeric index allows us to later combine it into a single feature vector, which we’ll use for model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "63b1d87b-9a8a-4cb0-826c-6dea4814f4dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+--------------------+-----------------+------------------+---------------+\n",
      "|Volume_Produced|Brewhouse_Efficiency|Number_of_Batches|       Total_Sales|Brew_Year_Index|\n",
      "+---------------+--------------------+-----------------+------------------+---------------+\n",
      "|            593|   85.73496269913532|          2500873|14362.653665879505|            0.0|\n",
      "|           4894|   85.26361099177572|          2500873|11852.097970324789|            0.0|\n",
      "|           4486|   89.49078286225225|          2500873|1665.1818593163712|            0.0|\n",
      "|           3809|   88.37087230231108|          2500873| 5925.879914754564|            0.0|\n",
      "|           4727|   70.66652472059178|          2500873|19228.362127803455|            0.0|\n",
      "+---------------+--------------------+-----------------+------------------+---------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Show the resulting DataFrame with the indexed Brew_Year\n",
    "df_selected.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1530fc65-0264-4afa-ac64-fbe7cf4ea424",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+\n",
      "|Brew_Year_Index|\n",
      "+---------------+\n",
      "|            0.0|\n",
      "|            3.0|\n",
      "|            2.0|\n",
      "|            1.0|\n",
      "+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_selected.select(\"Brew_Year_Index\").distinct().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97852211-b277-4f80-b478-ff1644e82106",
   "metadata": {},
   "source": [
    "VectorAssembler: Combine all features into a single vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a2e8b09e-3f69-4800-9a51-3189f71b984f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|            features|\n",
      "+--------------------+\n",
      "|[593.0,85.7349626...|\n",
      "|[4894.0,85.263610...|\n",
      "|[4486.0,89.490782...|\n",
      "|[3809.0,88.370872...|\n",
      "|[4727.0,70.666524...|\n",
      "+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "# Step 1: Define the feature columns\n",
    "feature_columns = ['Volume_Produced', 'Brewhouse_Efficiency', 'Number_of_Batches', 'Total_Sales', 'Brew_Year_Index']\n",
    "\n",
    "# Step 2: Create the VectorAssembler\n",
    "assembler = VectorAssembler(inputCols=feature_columns, outputCol=\"features\")\n",
    "\n",
    "# Step 3: Transform the DataFrame\n",
    "df_transformed = assembler.transform(df_selected)\n",
    "\n",
    "# Step 4: Show the result (including the 'features' column)\n",
    "df_transformed.select(\"features\").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b5ba84b-20b6-4929-a885-8a914c91d233",
   "metadata": {},
   "source": [
    "The VectorAssembler is used in machine learning workflows to combine multiple individual feature columns into a single vector column. This is necessary because most machine learning algorithms in Spark (and other ML frameworks) expect input data in a specific format—typically as a single column of vectors, where each vector represents a row of feature values.\n",
    "\n",
    "Reasons for using VectorAssembler:\n",
    "Required Input Format: Machine learning algorithms in Spark expect a single column containing a vector for the features, rather than multiple columns. The VectorAssembler consolidates all the feature columns (e.g., numerical, categorical) into a single vector column.\n",
    "\n",
    "Simplicity and Efficiency: It simplifies data manipulation, especially when working with many features. Rather than manually combining each feature, VectorAssembler automatically handles this process, saving time and reducing errors.\n",
    "\n",
    "Facilitates Model Training: Once the features are assembled into a vector, they can be directly fed into Spark’s machine learning models like regression, classification, and clustering. Without this step, these models would not be able to accept the input data.\n",
    "\n",
    "In essence, the VectorAssembler prepares the data for use in machine learning algorithms by transforming it into the required vector format, making it a crucial step in most Spark ML workflows."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36d59d5e-7ca1-4c15-b769-ed069b0963e5",
   "metadata": {},
   "source": [
    "Model evaluation: Evaluate the model using metrics such as RMSE for regression or\r\n",
    "accuracy/F1-score for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0e1b20a9-b0a8-48c6-9b37-8ef16305295e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'Total_Sales' is the target column\n",
    "\n",
    "# Step 1: Define the target and feature columns\n",
    "target_column = 'Total_Sales'\n",
    "\n",
    "# Step 2: Split the data into training and test sets\n",
    "train_df, test_df = df_transformed.randomSplit([0.8, 0.2], seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "bceccb55-787c-473e-a6c8-bc1cba28e63a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Initialize the Random Forest Regressor\n",
    "rf = RandomForestRegressor(featuresCol=\"features\", labelCol=target_column)\n",
    "\n",
    "# Step 3: Train the model on the training data\n",
    "rf_model = rf.fit(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b15749d6-670e-4411-883d-e54fc69dc28f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------------+------------------+\n",
      "|            features|        prediction|       Total_Sales|\n",
      "+--------------------+------------------+------------------+\n",
      "|[500.0,70.0686782...| 4357.217992752436|3168.6924853628825|\n",
      "|[500.0,70.2252333...|16541.635464101542|15666.325745637327|\n",
      "|[500.0,70.2668015...|  12672.3196317226|11095.155580607869|\n",
      "|[500.0,70.4654092...| 4184.369720752677| 4418.922397793351|\n",
      "|[500.0,70.6384091...| 12715.37223075588|12620.931290672395|\n",
      "+--------------------+------------------+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Step 4: Make predictions on the test set\n",
    "predictions = rf_model.transform(test_df)\n",
    "\n",
    "# Step 5: Show the predictions (optional)\n",
    "predictions.select(\"features\", \"prediction\", target_column).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "224ec318-f6c3-4be8-b5ec-da4a13d4664d",
   "metadata": {},
   "source": [
    "While there are some variances, these differences are relatively small in the context of the sales figures, supporting the strong performance metrics (high R² and low RMSE).\n",
    "\n",
    "Overall Insight:\n",
    "\n",
    "The model is accurately predicting Total_Sales with a high degree of reliability, evidenced by the close alignment between predictions and actual values across different feature combinations. Minor differences suggest room for marginal improvements, but overall, the model is performing well in approximating Total_Sales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9d252995-cab8-4170-b84f-780ae8965594",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error (RMSE): 1250.358281977003\n",
      "R2: 0.94806040370784\n"
     ]
    }
   ],
   "source": [
    "# Step 6: Evaluate the model using RMSE and R2\n",
    "evaluator_rmse = RegressionEvaluator(labelCol=target_column, predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "evaluator_r2 = RegressionEvaluator(labelCol=target_column, predictionCol=\"prediction\", metricName=\"r2\")\n",
    "\n",
    "# Compute RMSE and R2\n",
    "rmse = evaluator_rmse.evaluate(predictions)\n",
    "r2 = evaluator_r2.evaluate(predictions)\n",
    "\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse}\")\n",
    "print(f\"R2: {r2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd81dceb-ee5b-4cd4-8dfc-de1754804197",
   "metadata": {},
   "source": [
    "RMSE represents the square root of the average squared differences between predicted and actual values. In simple terms, it gives you the average error magnitude in the units of your target variable (in this case, Total_Sales).\n",
    "\n",
    "Generally, the lower the RMSE, the better the model, but whether this value is acceptable depends on the scale of your target variable. For example, if Total_Sales typically ranges in the thousands or millions, an RMSE of around 1250 may be reasonable. If the values are much smaller, the RMSE might be relatively high, suggesting room for improvement.\n",
    "\n",
    "R²: 0.9481\n",
    "\n",
    "The R² (Coefficient of Determination) indicates how well your model can explain the variance in the target variable, Total_Sales. In this case, 0.9481 means that the model explains about 94.81% of the variance in Total_Sales.\n",
    "\n",
    "An R² value close to 1 suggests a strong model fit. A value of 0.9481 is very good, indicating that the model does a great job of predicting sales, with only a small portion of the variance left unexplained.\n",
    "\n",
    "\n",
    "Good Model Fit: With an R² of 0.9481, your model explains a high percentage of the variance in Total_Sales, which suggests that your model is quite effective.\n",
    "\n",
    "Moderate Error (RMSE): The RMSE value of 1250.36 suggests that while your model's predictions are quite accurate, there is still some room for improvement\n",
    "\n",
    "Model Performance: The combination of a low RMSE and high R² suggests that your Random Forest model is performing well, with good predictive power, even though there are small errors. It's a solid model to work with, and improvements could make it even better.\n",
    "\n",
    "Conclusion:\n",
    "The model is providing solid predictions with an R² of around 94.81%, indicating strong performance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "60b1473f-cb7e-4fef-8a14-8a72cc7d6f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "\n",
    "# Step 7: Hyperparameter tuning (optional)\n",
    "paramGrid = (ParamGridBuilder()\n",
    "             .addGrid(rf.numTrees, [10, 20])\n",
    "             .addGrid(rf.maxDepth, [5, 10])\n",
    "             .build())\n",
    "\n",
    "crossval = CrossValidator(estimator=rf, estimatorParamMaps=paramGrid, evaluator=evaluator_rmse, numFolds=3)\n",
    "\n",
    "# Step 8: Train the model with hyperparameter tuning\n",
    "cv_model = crossval.fit(train_df)\n",
    "best_model = cv_model.bestModel\n",
    "\n",
    "# Step 9: Make predictions with the best model\n",
    "best_predictions = best_model.transform(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "133903d3-0da6-41cf-82d9-a16bef47e00e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE: 411.9342990211842\n",
      "Test R²: 0.9943625133289884\n"
     ]
    }
   ],
   "source": [
    "# Initialize evaluator with target metric\n",
    "evaluator_rmse = RegressionEvaluator(labelCol=\"Total_Sales\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "evaluator_r2 = RegressionEvaluator(labelCol=\"Total_Sales\", predictionCol=\"prediction\", metricName=\"r2\")\n",
    "\n",
    "# Compute RMSE and R²\n",
    "rmse = evaluator_rmse.evaluate(best_predictions)\n",
    "r2 = evaluator_r2.evaluate(best_predictions)\n",
    "\n",
    "print(f\"Test RMSE: {rmse}\")\n",
    "print(f\"Test R²: {r2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99e8cb20-60e8-4c71-92ee-e635d7299f16",
   "metadata": {},
   "source": [
    "Root Mean Squared Error (RMSE): 411.93\n",
    "\n",
    "The RMSE value represents the average error in terms of units of the target variable (Total_Sales) across the test set. An RMSE of ~411 suggests that, on average, the predictions are off by around 411 units. Given the scale of your Total_Sales values, this indicates relatively low error and good accuracy.\n",
    "\n",
    "R-squared (R²): 0.994\n",
    "\n",
    "The R² value, which is 0.994, indicates that your model explains about 99.4% of the variance in Total_Sales. This high R² suggests that the model captures most of the variability in the data, leaving very little unexplained variance. It’s an excellent result and shows that the model has a strong fit to the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b644ebb-64b3-4271-a13a-4c6d487e4dbb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
