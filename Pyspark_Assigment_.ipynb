{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d32dbfe0-f9f9-427e-8e93-6637d169e992",
   "metadata": {},
   "source": [
    "PySpark Assignment: Data Cleaning, Transformation, Analysis, and Prediction\n",
    "\r\n",
    "Student:Angel Ivan Reyes Torresa ID: C0053883\r\n",
    "\r\n",
    "Dataset Info:\r\n",
    "\r\n",
    "NBrewery Operations and Market Analysis Dataset\n",
    "\n",
    "a2.6gb file size\n",
    "\n",
    "\r",
    "Total rows in dataset 10000000138GB\r\n",
    "\n",
    "\n",
    "https://www.kaggle.com/datasets/ankurnapa/brewery-operations-and-market-analysis-dataset?select=brewery_data_complete_extended.csv\n",
    "\n",
    "This dataset presents an extensive collection of data from a craft beer brewery, spanning from January 2020 to January 2024. It encapsulates a rich blend of brewing parameters, sales data, and quality assessments, providing a holistic view of the brewing process and its market implications.\n",
    "\n",
    "Contain 20 columnsong others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d490df16-78e2-4072-9271-9733bba63aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from functools import reduce\n",
    "import matplotlib.pyplot as plt\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.ml.feature import StringIndexer, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from pyspark.ml.classification import LinearSVC\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pyspark.ml.regression import RandomForestRegressor\n",
    "from pyspark.ml.feature import StringIndexer, VectorAssembler, StandardScaler\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder, ParamGridBuilder\n",
    "from pyspark.sql.types import FloatType, DoubleType, IntegerType\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator, BinaryClassificationEvaluator, RegressionEvaluator\n",
    "from pyspark.sql.functions import col, count, when, isnan, to_date, year, month, dayofweek, dayofyear, avg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11de8094-b5e6-4c41-8b5f-2ec95a644b37",
   "metadata": {},
   "source": [
    "1 Data Loading and Initial Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "305be14d-e646-48ab-b26e-35e69c96757b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start a Spark session with optimized configurations for handling large datasets\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"BreweryDataAnalysis\") \\\n",
    "    .config(\"spark.driver.memory\", \"16g\") \\\n",
    "    .config(\"spark.executor.memory\", \"16g\") \\\n",
    "    .config(\"spark.sql.shuffle.partitions\", \"100\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "caf373c8-831b-4c2f-a90b-6a96b701469e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset with an appropriate number of partitions\n",
    "file_path = \"C:/Users/angel/00Angel/brewery_data.csv\"\n",
    "df = spark.read.csv(file_path, header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "22fba1e8-682f-4c68-88f9-2b2cce3e6510",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Batch_ID: integer (nullable = true)\n",
      " |-- Brew_Date: timestamp (nullable = true)\n",
      " |-- Beer_Style: string (nullable = true)\n",
      " |-- SKU: string (nullable = true)\n",
      " |-- Location: string (nullable = true)\n",
      " |-- Fermentation_Time: integer (nullable = true)\n",
      " |-- Temperature: double (nullable = true)\n",
      " |-- pH_Level: double (nullable = true)\n",
      " |-- Gravity: double (nullable = true)\n",
      " |-- Alcohol_Content: double (nullable = true)\n",
      " |-- Bitterness: integer (nullable = true)\n",
      " |-- Color: integer (nullable = true)\n",
      " |-- Ingredient_Ratio: string (nullable = true)\n",
      " |-- Volume_Produced: integer (nullable = true)\n",
      " |-- Total_Sales: double (nullable = true)\n",
      " |-- Quality_Score: double (nullable = true)\n",
      " |-- Brewhouse_Efficiency: double (nullable = true)\n",
      " |-- Loss_During_Brewing: double (nullable = true)\n",
      " |-- Loss_During_Fermentation: double (nullable = true)\n",
      " |-- Loss_During_Bottling_Kegging: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check the schema to see data types and structure\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ea7a487c-26cd-46df-889a-904403205d47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------------------+----------+-------+---------------+-----------------+------------------+------------------+------------------+-----------------+----------+-----+----------------+---------------+------------------+-----------------+--------------------+-------------------+------------------------+----------------------------+\n",
      "|Batch_ID|Brew_Date          |Beer_Style|SKU    |Location       |Fermentation_Time|Temperature       |pH_Level          |Gravity           |Alcohol_Content  |Bitterness|Color|Ingredient_Ratio|Volume_Produced|Total_Sales       |Quality_Score    |Brewhouse_Efficiency|Loss_During_Brewing|Loss_During_Fermentation|Loss_During_Bottling_Kegging|\n",
      "+--------+-------------------+----------+-------+---------------+-----------------+------------------+------------------+------------------+-----------------+----------+-----+----------------+---------------+------------------+-----------------+--------------------+-------------------+------------------------+----------------------------+\n",
      "|7870796 |2020-01-01 00:00:19|Wheat Beer|Kegs   |Whitefield     |16               |24.204250857069873|5.2898454476095615|1.0395041267301979|5.370842159553436|20        |5    |1:0.32:0.16     |4666           |2664.7593448382822|8.57701633109399 |89.19588216376087   |4.1049876591878345 |3.2354851724654683      |4.663204448186049           |\n",
      "|9810411 |2020-01-01 00:00:31|Sour      |Kegs   |Whitefield     |13               |18.086762947259544|5.275643382756193 |1.0598189516987164|5.096053082797625|36        |14   |1:0.39:0.24     |832            |9758.801062471319 |7.420540752553908|72.4809153900275    |2.6765280953921122 |4.2461292104108574      |2.04435836917023            |\n",
      "|2623342 |2020-01-01 00:00:40|Wheat Beer|Kegs   |Malleswaram    |12               |15.539332669116469|4.7780156232459765|1.0374757095487201|4.824737120959184|30        |10   |1:0.35:0.16     |2115           |11721.087016274963|8.451364886803127|86.32214396020584   |3.299893625514981  |3.109440467362847       |3.0338798378762806          |\n",
      "|8114651 |2020-01-01 00:01:37|Ale       |Kegs   |Rajajinagar    |17               |16.41848910394318 |5.345260585546188 |1.0524314251694946|5.509243080797997|48        |18   |1:0.35:0.15     |3173           |12050.177463190277|9.671859404043175|83.09494037181545   |2.136055116262562  |4.634254174098425       |1.4898890677148424          |\n",
      "|4579587 |2020-01-01 00:01:43|Stout     |Cans   |Marathahalli   |18               |19.144907654338517|4.86185374113861  |1.0542961149482333|5.133624684263243|57        |13   |1:0.46:0.11     |4449           |5515.0774647529615|7.895333676172065|88.62583302052388   |4.491723843594972  |2.1833886016455497      |2.9906302188791485          |\n",
      "|8715759 |2020-01-01 00:01:48|Ale       |Kegs   |Whitefield     |10               |17.424614393375766|5.291786621908058 |1.064662042682204 |4.859171021614226|45        |9    |1:0.23:0.15     |3752           |6278.389850288936 |8.47381192497374 |87.8128259096688    |3.2051089361121203 |1.4783386754434935      |3.051920588503346           |\n",
      "|6441292 |2020-01-01 00:01:49|Lager     |Pints  |Electronic City|16               |15.629810875902074|5.3328812410204325|1.0466885050091976|4.710402522822796|44        |8    |1:0.34:0.16     |593            |14362.653665879505|6.958182685507612|85.73496269913532   |3.955331969978375  |1.6229792325278112      |1.566344313315546           |\n",
      "|8843420 |2020-01-01 00:01:51|Wheat Beer|Cans   |Indiranagar    |13               |21.605469689190052|4.507213419450749 |1.0415809900303394|4.83702482975061 |38        |9    |1:0.45:0.26     |4949           |1082.3549117830858|6.295632960105362|73.43876487534912   |1.7047005571803084 |1.7187729863809476      |1.0336558740315214          |\n",
      "|5713096 |2020-01-01 00:02:16|Stout     |Bottles|Electronic City|18               |20.183530075814367|5.224481542948347 |1.0764413828584096|5.133596661986578|25        |15   |1:0.39:0.19     |2451           |7392.644809330611 |9.660185081725519|83.26770612274336   |4.765479207857815  |2.3862457622492697      |4.453829514148623           |\n",
      "|8178852 |2020-01-01 00:02:32|Stout     |Cans   |Electronic City|11               |17.237974924919577|4.911261716318917 |1.0478298509908957|5.709899253603638|48        |10   |1:0.43:0.17     |4305           |7648.2830929155325|9.348719159247096|73.60380329779937   |3.8425385336431    |4.284796713900535       |1.3128481660547955          |\n",
      "+--------+-------------------+----------+-------+---------------+-----------------+------------------+------------------+------------------+-----------------+----------+-----+----------------+---------------+------------------+-----------------+--------------------+-------------------+------------------------+----------------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Show the first 10 rows to inspect data quality and format\n",
    "df.show(10, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "33d399d5-7d78-4e2b-8dc0-b46d55513f52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows in dataset: 10000000\n"
     ]
    }
   ],
   "source": [
    "# Count the total number of rows in the dataset\n",
    "row_count = df.count()\n",
    "print(f\"Total rows in dataset: {row_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89642a1d-a9aa-4eae-9b12-bc06614a1e9c",
   "metadata": {},
   "source": [
    "2 Data Cleaning and Transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bf1ff2c-f5e4-4106-b650-c77a430f0c13",
   "metadata": {},
   "source": [
    "2.1. Handling Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "96b56a20-8e35-4d57-aa74-0c2adb4593e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---------+----------+---+--------+-----------------+-----------+--------+-------+---------------+----------+-----+----------------+---------------+-----------+-------------+--------------------+-------------------+------------------------+----------------------------+\n",
      "|Batch_ID|Brew_Date|Beer_Style|SKU|Location|Fermentation_Time|Temperature|pH_Level|Gravity|Alcohol_Content|Bitterness|Color|Ingredient_Ratio|Volume_Produced|Total_Sales|Quality_Score|Brewhouse_Efficiency|Loss_During_Brewing|Loss_During_Fermentation|Loss_During_Bottling_Kegging|\n",
      "+--------+---------+----------+---+--------+-----------------+-----------+--------+-------+---------------+----------+-----+----------------+---------------+-----------+-------------+--------------------+-------------------+------------------------+----------------------------+\n",
      "|       0|        0|         0|  0|       0|                0|          0|       0|      0|              0|         0|    0|               0|              0|          0|            0|                   0|                  0|                       0|                           0|\n",
      "+--------+---------+----------+---+--------+-----------------+-----------+--------+-------+---------------+----------+-----+----------------+---------------+-----------+-------------+--------------------+-------------------+------------------------+----------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Count missing values (nulls) for each column\n",
    "missing_values = df.select([count(when(col(c).isNull(), c)).alias(c) for c in df.columns])\n",
    "\n",
    "# Show the result\n",
    "missing_values.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ec54139a-0522-40d9-87dd-1ebae5f2f051",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned = df.dropna()  # Removes rows with any null value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e1a528e6-195b-44b0-8b9f-cf0af7406d0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows in dataset: 10000000\n"
     ]
    }
   ],
   "source": [
    "row_count = df_cleaned.count()\n",
    "print(f\"Total rows in dataset: {row_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "88b606bb-e37b-4ba0-92d7-6cf9f3b7b697",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---------+----------+---+--------+-----------------+-----------+--------+-------+---------------+----------+-----+----------------+---------------+-----------+-------------+--------------------+-------------------+------------------------+----------------------------+-----+\n",
      "|Batch_ID|Brew_Date|Beer_Style|SKU|Location|Fermentation_Time|Temperature|pH_Level|Gravity|Alcohol_Content|Bitterness|Color|Ingredient_Ratio|Volume_Produced|Total_Sales|Quality_Score|Brewhouse_Efficiency|Loss_During_Brewing|Loss_During_Fermentation|Loss_During_Bottling_Kegging|count|\n",
      "+--------+---------+----------+---+--------+-----------------+-----------+--------+-------+---------------+----------+-----+----------------+---------------+-----------+-------------+--------------------+-------------------+------------------------+----------------------------+-----+\n",
      "+--------+---------+----------+---+--------+-----------------+-----------+--------+-------+---------------+----------+-----+----------------+---------------+-----------+-------------+--------------------+-------------------+------------------------+----------------------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Show the duplicate records (based on all columns)\n",
    "duplicates_df = df.groupBy(df.columns).count().filter(\"count > 1\")\n",
    "duplicates_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce882dd0-750c-49b2-ace9-e06ca31d197f",
   "metadata": {},
   "source": [
    "2.3. Data Type Conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4e8f1f1e-69f2-40a7-8cc6-94fb8791826c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|Brew_Date |\n",
      "+----------+\n",
      "|2020-01-01|\n",
      "|2020-01-01|\n",
      "|2020-01-01|\n",
      "|2020-01-01|\n",
      "|2020-01-01|\n",
      "+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Convert 'Brew_Date' column to date only (removes time part)\n",
    "df = df.withColumn('Brew_Date', to_date(df['Brew_Date']))\n",
    "\n",
    "# Show the result to confirm the changes\n",
    "df.select('Brew_Date').show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1f140d88-3639-45e0-96fd-3dc3fc5d2c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned = df.withColumn('Fermentation_Time', df['Fermentation_Time'].cast('integer'))\n",
    "df_cleaned = df.withColumn('Brew_Date', df['Brew_Date'].cast('timestamp'))\n",
    "df_cleaned = df.withColumn('Temperature', df['Temperature'].cast('double'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0aea267-3fb9-4bde-867d-c8b7bc81ca61",
   "metadata": {},
   "source": [
    "2.4. Filtering Out Invalid Rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1dd393e2-e7ec-4c49-b1dc-01f72ab3f7b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out rows with invalid or impossible values\n",
    "df_cleaned = df_cleaned.filter((df_cleaned['Volume_Produced'] >= 0) & \n",
    "                               (df_cleaned['Temperature'] >= 0) & (df_cleaned['Temperature'] <= 100) & \n",
    "                               (df_cleaned['pH_Level'] >= 0) & (df_cleaned['pH_Level'] <= 14))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd75fac3-b16d-428c-b8f2-7297a783fe9e",
   "metadata": {},
   "source": [
    "1  Volume_Produced >= 0\n",
    "\n",
    "Reason: The volume of beer produced (Volume_Produced) cannot be negative because it represents the actual quantity of beer brewed. Negative values would indicate an impossible or erroneous record. So, filtering out values less than zero is essential to ensure data validity.\n",
    "\n",
    "2  Temperature >= 0 and Temperature <= 100\n",
    "\n",
    "Reason: Minimum Temperature (0°C): The minimum possible temperature for water or beer is 0°C (freezing point of water). Temperatures below this could indicate data errors, such as negative values that don’t make sense in the context of brewing processes.\n",
    "\n",
    "Maximum Temperature (100°C): 100°C is the boiling point of water at sea level. While brewing temperatures are typically below 100°C, extreme temperatures above 100°C would also be unusual. Therefore, this range is reasonable to filter out outliers or incorrect readings.\n",
    "Brewing Temperature: Generally, brewing temperatures range between 60°C to 75°C for most beer styles. While this range is broader (0–100°C) to account for potential outliers, it still removes obviously invalid or extreme data points.\n",
    "\n",
    "3 pH_Level >= 0 and pH_Level <= 14\n",
    "\n",
    "Reason: Minimum pH (0): The pH scale ranges from 0 to 14, with 0 being extremely acidic and 14 being extremely alkaline. A pH level below 0 is physically impossible for a solution, so filtering values below 0 is necessary to remove errors.\n",
    "\n",
    "Maximum pH (14): Similarly, a pH level above 14 is impossible in the context of beer brewing. Typical beer pH values range between 4.0 and 5.5, with some variation depending on the type of beer and fermentation conditions. Filtering values greater than 14 ensures that any erroneous or outlier values above the maximum pH scale are removed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d37c324-6952-4df3-ad14-612075bb9116",
   "metadata": {},
   "source": [
    "3 Data Analysis Using Spark SQL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "651f8f2f-a09d-4d58-a5c5-f8b99f1ec1d0",
   "metadata": {},
   "source": [
    "3.1.1) Aggregation: Calculate summary statistics (e.g., mean, median, standard deviation) of the numerical columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "68c94afb-b889-4773-b9fd-9b832126f88d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = df_cleaned\n",
    "df_final.createOrReplaceTempView(\"brewing_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fbe7da7a-b273-43c7-b7af-80716c513b86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+----------+----+------------+-----------------+------------------+------------------+------------------+-----------------+----------+-----+----------------+---------------+------------------+-----------------+--------------------+-------------------+------------------------+----------------------------+\n",
      "|Batch_ID| Brew_Date|Beer_Style| SKU|    Location|Fermentation_Time|       Temperature|          pH_Level|           Gravity|  Alcohol_Content|Bitterness|Color|Ingredient_Ratio|Volume_Produced|       Total_Sales|    Quality_Score|Brewhouse_Efficiency|Loss_During_Brewing|Loss_During_Fermentation|Loss_During_Bottling_Kegging|\n",
      "+--------+----------+----------+----+------------+-----------------+------------------+------------------+------------------+-----------------+----------+-----+----------------+---------------+------------------+-----------------+--------------------+-------------------+------------------------+----------------------------+\n",
      "| 7870796|2020-01-01|Wheat Beer|Kegs|  Whitefield|               16|24.204250857069873|5.2898454476095615|1.0395041267301979|5.370842159553436|        20|    5|     1:0.32:0.16|           4666|2664.7593448382822| 8.57701633109399|   89.19588216376087| 4.1049876591878345|      3.2354851724654683|           4.663204448186049|\n",
      "| 9810411|2020-01-01|      Sour|Kegs|  Whitefield|               13|18.086762947259544| 5.275643382756193|1.0598189516987164|5.096053082797625|        36|   14|     1:0.39:0.24|            832| 9758.801062471319|7.420540752553908|    72.4809153900275| 2.6765280953921122|      4.2461292104108574|            2.04435836917023|\n",
      "| 2623342|2020-01-01|Wheat Beer|Kegs| Malleswaram|               12|15.539332669116469|4.7780156232459765|1.0374757095487201|4.824737120959184|        30|   10|     1:0.35:0.16|           2115|11721.087016274963|8.451364886803127|   86.32214396020584|  3.299893625514981|       3.109440467362847|          3.0338798378762806|\n",
      "| 8114651|2020-01-01|       Ale|Kegs| Rajajinagar|               17| 16.41848910394318| 5.345260585546188|1.0524314251694946|5.509243080797997|        48|   18|     1:0.35:0.15|           3173|12050.177463190277|9.671859404043175|   83.09494037181545|  2.136055116262562|       4.634254174098425|          1.4898890677148424|\n",
      "| 4579587|2020-01-01|     Stout|Cans|Marathahalli|               18|19.144907654338517|  4.86185374113861|1.0542961149482333|5.133624684263243|        57|   13|     1:0.46:0.11|           4449|5515.0774647529615|7.895333676172065|   88.62583302052388|  4.491723843594972|      2.1833886016455497|          2.9906302188791485|\n",
      "+--------+----------+----------+----+------------+-----------------+------------------+------------------+------------------+-----------------+----------+-----+----------------+---------------+------------------+-----------------+--------------------+-------------------+------------------------+----------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Performing a SQL query to select all data from the brewing_data view\n",
    "cleaned_data_query = \"SELECT * FROM brewing_data\"\n",
    "final_df = spark.sql(cleaned_data_query)\n",
    "\n",
    "# Showing the first few rows of the cleaned data\n",
    "final_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0f5dcd32-e2b1-41a1-80aa-2c5e8ee5a2e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+---------------------+------------------+-----------------+------------------+-------------------+--------------+----------+-------------------+------------------+-----------------+------------------------+-----------------------+----------------------------+--------------------------------+---------------+------------------------+------------------+-----------------+------------------+----------------------+-----------------+------------+----------------------+------------------+--------------------+---------------------------+--------------------------+-------------------------------+-----------------------------------+------------------+------------------------+------------------+-------------------+--------------------+----------------------+------------------+-----------------+----------------------+------------------+--------------------+---------------------------+--------------------------+-------------------------------+-----------------------------------+\n",
      "|avg_Batch_ID|avg_Fermentation_Time|avg_Temperature   |avg_pH_Level     |avg_Gravity       |avg_Alcohol_Content|avg_Bitterness|avg_Color |avg_Volume_Produced|avg_Total_Sales   |avg_Quality_Score|avg_Brewhouse_Efficiency|avg_Loss_During_Brewing|avg_Loss_During_Fermentation|avg_Loss_During_Bottling_Kegging|median_Batch_ID|median_Fermentation_Time|median_Temperature|median_pH_Level  |median_Gravity    |median_Alcohol_Content|median_Bitterness|median_Color|median_Volume_Produced|median_Total_Sales|median_Quality_Score|median_Brewhouse_Efficiency|median_Loss_During_Brewing|median_Loss_During_Fermentation|median_Loss_During_Bottling_Kegging|stddev_Batch_ID   |stddev_Fermentation_Time|stddev_Temperature|stddev_pH_Level    |stddev_Gravity      |stddev_Alcohol_Content|stddev_Bitterness |stddev_Color     |stddev_Volume_Produced|stddev_Total_Sales|stddev_Quality_Score|stddev_Brewhouse_Efficiency|stddev_Loss_During_Brewing|stddev_Loss_During_Fermentation|stddev_Loss_During_Bottling_Kegging|\n",
      "+------------+---------------------+------------------+-----------------+------------------+-------------------+--------------+----------+-------------------+------------------+-----------------+------------------------+-----------------------+----------------------------+--------------------------------+---------------+------------------------+------------------+-----------------+------------------+----------------------+-----------------+------------+----------------------+------------------+--------------------+---------------------------+--------------------------+-------------------------------+-----------------------------------+------------------+------------------------+------------------+-------------------+--------------------+----------------------+------------------+-----------------+----------------------+------------------+--------------------+---------------------------+--------------------------+-------------------------------+-----------------------------------+\n",
      "|4999999.5   |14.500898            |19.999898511018827|4.999940543893489|1.0550028700788692|5.249709006579308  |39.4961996    |11.9993459|2749.0309594       |10497.785343940232|7.999825148192516|80.00091934182497       |3.000081497042524      |3.000002413212497           |3.0001587106749747              |4999672        |15                      |19.999639059280874|4.999862833836904|1.0550036147017112|5.249840017352465     |39               |12          |2749                  |10495.819326532543|7.999859661747688   |80.00193042786057          |2.999649890349522         |2.999689053088824              |3.000579322020188                  |2886751.4902856858|2.872006096518228       |2.8870297120328576|0.28863762894103545|0.014434649211836703|0.43296144791729213   |11.545572488490313|4.321170228005893|1299.078133259011     |5485.995544804044 |1.1546793056214646  |5.7749295785811645         |1.1547483756083143        |1.1548266863212513             |1.1547186092997934                 |\n",
      "+------------+---------------------+------------------+-----------------+------------------+-------------------+--------------+----------+-------------------+------------------+-----------------+------------------------+-----------------------+----------------------------+--------------------------------+---------------+------------------------+------------------+-----------------+------------------+----------------------+-----------------+------------+----------------------+------------------+--------------------+---------------------------+--------------------------+-------------------------------+-----------------------------------+------------------+------------------------+------------------+-------------------+--------------------+----------------------+------------------+-----------------+----------------------+------------------+--------------------+---------------------------+--------------------------+-------------------------------+-----------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Identifying numeric columns in the cleaned data\n",
    "numeric_columns = [field.name for field in final_df.schema.fields \n",
    "                   if isinstance(field.dataType, (FloatType, DoubleType, IntegerType))]\n",
    "\n",
    "# Generating SQL queries for summary statistics (mean, median, standard deviation)\n",
    "summary_query = f\"\"\"\n",
    "SELECT \n",
    "    {', '.join([f'AVG({col}) AS avg_{col}' for col in numeric_columns])},\n",
    "    {', '.join([f'PERCENTILE_APPROX({col}, 0.5) AS median_{col}' for col in numeric_columns])},\n",
    "    {', '.join([f'STDDEV({col}) AS stddev_{col}' for col in numeric_columns])}\n",
    "FROM brewing_data\n",
    "\"\"\"\n",
    "\n",
    "# Executing the SQL query to calculate summary statistics\n",
    "summary_df = spark.sql(summary_query)\n",
    "\n",
    "# Showing the summary statistics DataFrame\n",
    "summary_df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e018d398-5d6c-4f81-bf69-9d521ce247b4",
   "metadata": {},
   "source": [
    "3.1.2) Grouping and Filtering: Group data by specific categories and calculate aggregations for each group. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d3b3054-c1e7-4c72-a2c2-d00a58d50604",
   "metadata": {},
   "source": [
    "Highest Total_Sales per Brew_Date and Beer_Style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7ea6484d-1dd4-41b7-ac9f-f4377ca6e4f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+-------------------+\n",
      "|Brew_Date |Beer_Style|Highest_Total_Sales|\n",
      "+----------+----------+-------------------+\n",
      "|2023-12-31|Sour      |19999.957753273946 |\n",
      "|2023-12-31|Porter    |19998.713582154644 |\n",
      "|2023-12-31|Pilsner   |19998.166499284678 |\n",
      "|2023-12-31|Stout     |19991.554562673293 |\n",
      "|2023-12-31|Wheat Beer|19988.27588543136  |\n",
      "|2023-12-31|Lager     |19980.77426642725  |\n",
      "|2023-12-31|Ale       |19965.82561229111  |\n",
      "|2023-12-31|IPA       |19956.92365618578  |\n",
      "|2023-12-30|Ale       |19996.39620222792  |\n",
      "|2023-12-30|IPA       |19992.75046454753  |\n",
      "+----------+----------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# SQL query to find the highest Total_Sales per Brew_Date and Beer_Style, ordered by date\n",
    "aggregation_query = \"\"\"\n",
    "SELECT \n",
    "    Brew_Date,\n",
    "    Beer_Style,\n",
    "    MAX(Total_Sales) AS Highest_Total_Sales\n",
    "FROM brewing_data\n",
    "GROUP BY Brew_Date, Beer_Style\n",
    "ORDER BY Brew_Date DESC, Highest_Total_Sales DESC\n",
    "LIMIT 10\n",
    "\"\"\"\n",
    "\n",
    "# Execute the query\n",
    "result_df = spark.sql(aggregation_query)\n",
    "\n",
    "# Show the results\n",
    "result_df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7db9f61c-3ee3-4077-bb8d-db44b6c667ce",
   "metadata": {},
   "source": [
    "Highest Quality_Score per Brew_Date and Beer_Style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "40c1c354-acfd-45e1-9705-fd9d5a4d7c96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+---------------------+\n",
      "|Brew_Date |Beer_Style|Highest_Quality_Score|\n",
      "+----------+----------+---------------------+\n",
      "|2023-12-31|Sour      |9.999161865781595    |\n",
      "|2023-12-31|Pilsner   |9.998151783823628    |\n",
      "|2023-12-31|Ale       |9.9972227757805      |\n",
      "|2023-12-31|Porter    |9.99697217893943     |\n",
      "|2023-12-31|IPA       |9.996293456793538    |\n",
      "|2023-12-31|Wheat Beer|9.994572202670671    |\n",
      "|2023-12-31|Stout     |9.990243632639132    |\n",
      "|2023-12-31|Lager     |9.984752221429648    |\n",
      "|2023-12-30|Ale       |9.999722934959543    |\n",
      "|2023-12-30|IPA       |9.999592070600983    |\n",
      "+----------+----------+---------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# SQL query to find the highest Quality_Score per Brew_Date and Beer_Style, ordered by date\n",
    "aggregation_query = \"\"\"\n",
    "SELECT \n",
    "    Brew_Date,\n",
    "    Beer_Style,\n",
    "    MAX(Quality_Score) AS Highest_Quality_Score\n",
    "FROM brewing_data\n",
    "GROUP BY Brew_Date, Beer_Style\n",
    "ORDER BY Brew_Date DESC, Highest_Quality_Score DESC\n",
    "LIMIT 10\n",
    "\"\"\"\n",
    "\n",
    "# Execute the query\n",
    "result_df = spark.sql(aggregation_query)\n",
    "\n",
    "# Show the results\n",
    "result_df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90da86cb-6fae-4138-b414-37e867c817fb",
   "metadata": {},
   "source": [
    "Highest Volume_Produced per Brew_Date and Beer_Style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fcae1123-aed7-4c32-bc11-816440e43db6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+-----------------------+\n",
      "|Brew_Date |Beer_Style|Highest_Volume_Produced|\n",
      "+----------+----------+-----------------------+\n",
      "|2023-12-31|Ale       |4999                   |\n",
      "|2023-12-31|Pilsner   |4999                   |\n",
      "|2023-12-31|Stout     |4998                   |\n",
      "|2023-12-31|IPA       |4996                   |\n",
      "|2023-12-31|Sour      |4996                   |\n",
      "|2023-12-31|Lager     |4993                   |\n",
      "|2023-12-31|Wheat Beer|4990                   |\n",
      "|2023-12-31|Porter    |4986                   |\n",
      "|2023-12-30|Wheat Beer|4999                   |\n",
      "|2023-12-30|Lager     |4997                   |\n",
      "+----------+----------+-----------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# SQL query to find the highest Volume_Produced per Brew_Date and Beer_Style, ordered by date\n",
    "aggregation_query = \"\"\"\n",
    "SELECT \n",
    "    Brew_Date,\n",
    "    Beer_Style,\n",
    "    MAX(Volume_Produced) AS Highest_Volume_Produced\n",
    "FROM brewing_data\n",
    "GROUP BY Brew_Date, Beer_Style\n",
    "ORDER BY Brew_Date DESC, Highest_Volume_Produced DESC\n",
    "LIMIT 10\n",
    "\"\"\"\n",
    "\n",
    "# Execute the query\n",
    "result_df = spark.sql(aggregation_query)\n",
    "\n",
    "# Show the results\n",
    "result_df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b12c19f-9d0d-4788-a516-5461ca91b471",
   "metadata": {},
   "source": [
    "3.1.3) Joins: If applicable, perform a join between two tables\n",
    "\n",
    "Are not applicable for our dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e23df966-61d9-4c0a-8ae1-cba0f9ce8ab7",
   "metadata": {},
   "source": [
    "3.1.4) Time-based analysis: If your dataset contains a timestamp column, analyze trends over time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b30381bc-5e47-425a-9123-31142feea064",
   "metadata": {},
   "source": [
    "SQL query for number of batches and total sales per Brew_Date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5b363f19-60e1-46be-9f36-a71bda77a5d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------------+-------------------+\n",
      "|Brew_Date |Number_of_Batches|Total_Sales_Per_Day|\n",
      "+----------+-----------------+-------------------+\n",
      "|2023-12-31|6951             |7.402164022621739E7|\n",
      "|2023-12-30|6875             |7.277619057643037E7|\n",
      "|2023-12-29|6801             |7.101619643852998E7|\n",
      "|2023-12-28|6853             |7.161239863457432E7|\n",
      "|2023-12-27|6823             |7.105070785238072E7|\n",
      "|2023-12-26|6778             |7.173696041901506E7|\n",
      "|2023-12-25|6975             |7.328681953301111E7|\n",
      "|2023-12-24|6945             |7.398418149452E7   |\n",
      "|2023-12-23|6809             |7.171651056100419E7|\n",
      "|2023-12-22|6787             |7.072098217357387E7|\n",
      "+----------+-----------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# SQL query to find the number of batches and total sales per Brew_Date\n",
    "time_based_query = \"\"\"\n",
    "SELECT \n",
    "    Brew_Date,\n",
    "    COUNT(Batch_ID) AS Number_of_Batches,\n",
    "    SUM(Total_Sales) AS Total_Sales_Per_Day\n",
    "FROM brewing_data\n",
    "GROUP BY Brew_Date\n",
    "ORDER BY Brew_Date DESC\n",
    "LIMIT 10\n",
    "\"\"\"\n",
    "\n",
    "# Execute the query\n",
    "result_time_based_df = spark.sql(time_based_query)\n",
    "\n",
    "# Show the results\n",
    "result_time_based_df.show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16c5407a-9daf-41fd-a596-0c9d92a00777",
   "metadata": {},
   "source": [
    "SQL Query for Average Quality Score and Alcohol Content per Brew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "91688835-edf5-461e-b236-898f67488e89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------------------+-----------------------+\n",
      "|Brew_Date |Average_Quality_Score|Average_Alcohol_Content|\n",
      "+----------+---------------------+-----------------------+\n",
      "|2023-12-31|7.972432599968671    |5.247159001244369      |\n",
      "|2023-12-30|7.972838103070529    |5.246944176486663      |\n",
      "|2023-12-29|8.000243096635971    |5.2470258847132065     |\n",
      "|2023-12-28|8.01174732752383     |5.2542033652894995     |\n",
      "|2023-12-27|7.994104801119074    |5.239622772825028      |\n",
      "|2023-12-26|7.998919681970579    |5.245127095144804      |\n",
      "|2023-12-25|8.01056465475819     |5.244991263699129      |\n",
      "|2023-12-24|7.993671636436315    |5.253078226738263      |\n",
      "|2023-12-23|7.992270025832132    |5.248499193071808      |\n",
      "|2023-12-22|7.99786223144857     |5.257680459953336      |\n",
      "+----------+---------------------+-----------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# SQL query to find the average Quality Score and Alcohol Content per Brew_Date\n",
    "average_metrics_query = \"\"\"\n",
    "SELECT \n",
    "    Brew_Date,\n",
    "    AVG(Quality_Score) AS Average_Quality_Score,\n",
    "    AVG(Alcohol_Content) AS Average_Alcohol_Content\n",
    "FROM brewing_data\n",
    "GROUP BY Brew_Date\n",
    "ORDER BY Brew_Date DESC\n",
    "LIMIT 10\n",
    "\"\"\"\n",
    "\n",
    "# Execute the query\n",
    "result_average_metrics_df = spark.sql(average_metrics_query)\n",
    "\n",
    "# Show the results\n",
    "result_average_metrics_df.show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeb04c3d-2d4a-4f78-b270-dad299026fd7",
   "metadata": {},
   "source": [
    "SQL Query for Beer Style Count per Brew Date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "87591568-ff8f-439c-b6da-a8cd0a65da80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+----------------+\n",
      "|Brew_Date |Beer_Style|Beer_Style_Count|\n",
      "+----------+----------+----------------+\n",
      "|2023-12-31|Lager     |892             |\n",
      "|2023-12-31|Ale       |879             |\n",
      "|2023-12-31|Wheat Beer|877             |\n",
      "|2023-12-31|IPA       |876             |\n",
      "|2023-12-31|Stout     |876             |\n",
      "|2023-12-31|Pilsner   |864             |\n",
      "|2023-12-31|Sour      |853             |\n",
      "|2023-12-31|Porter    |834             |\n",
      "|2023-12-30|Sour      |905             |\n",
      "|2023-12-30|Stout     |901             |\n",
      "+----------+----------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# SQL query to count the number of each Beer Style produced per Brew_Date\n",
    "beer_style_count_query = \"\"\"\n",
    "SELECT \n",
    "    Brew_Date,\n",
    "    Beer_Style,\n",
    "    COUNT(*) AS Beer_Style_Count\n",
    "FROM brewing_data\n",
    "GROUP BY Brew_Date, Beer_Style\n",
    "ORDER BY Brew_Date DESC, Beer_Style_Count DESC\n",
    "LIMIT 10\n",
    "\"\"\"\n",
    "\n",
    "# Execute the query\n",
    "result_beer_style_count_df = spark.sql(beer_style_count_query)\n",
    "\n",
    "# Show the results\n",
    "result_beer_style_count_df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03ff03c9-cb88-422f-9f5e-4cfe550a54bd",
   "metadata": {},
   "source": [
    "Insights:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "791f8a30-5bca-453f-a098-7ce168c8c697",
   "metadata": {},
   "source": [
    "1 Highest Total Sales\n",
    "   \n",
    "Top Performers: On 2023-12-31, Sour beer led in total sales, followed closely by Porter, Pilsner, and Stout.\n",
    "Beer Style Performance: Most beer styles show high total sales on 2023-12-31, indicating that this was likely a peak day for sales overall.\n",
    "Sales Trend: The sales on 2023-12-30 were slightly lower, with Ale and IPA performing well, although sales for other styles were still significant.\n",
    "\n",
    "2 Highest Quality Score\n",
    "\n",
    "Top Performers: Sour beer had the highest quality score on 2023-12-31, followed by Pilsner and Ale. This suggests that consumers rated these beer styles very highly.\n",
    "Quality Consistency: Quality scores across all beer styles are consistently high, particularly on 2023-12-30, where the Ale beer style achieved almost a perfect score.\n",
    "\n",
    "3 Highest Volume Produced\n",
    "\n",
    "Volume Consistency: Ale and Pilsner beer styles led in volume produced on 2023-12-31, both reaching 4999 units, indicating significant production for these styles.\n",
    "Production Trends: Stout and IPA also had high production numbers, but the volume produced slightly dropped for some styles like Porter.\n",
    "\n",
    "4 Number of Batches and Sales per Day\n",
    "\n",
    "Batches and Sales Volume: 2023-12-31 recorded the highest number of batches (6951) and highest sales per day (around 74 million), suggesting that it was a high-volume production day.\n",
    "Sales Correlation: The total sales per day shows fluctuations but remains high on 2023-12-31. The data indicates a very active production and sales environment, possibly around the holiday season.\n",
    "\n",
    "5 Average Quality Score and Alcohol Content\n",
    "\n",
    "Consistency in Quality Score: The average quality scores remain high across all the days, with a slight dip on 2023-12-31.\n",
    "Alcohol Content: Average alcohol content remains relatively stable, with 2023-12-31 having an average of about 5.25%. This suggests no major variations in the types of beer produced during this period.\n",
    "\n",
    "6 Beer Style Count\n",
    "\n",
    "Lager and Ale Dominance: Lager and Ale were the most produced and sold beers on 2023-12-31, with Lager topping the list at 892 batches.\n",
    "Beer Style Spread: The number of batches for Sour and Porter were slightly lower compared to others, indicating less production or popularity during this period.\n",
    "\n",
    "Key Observations:\n",
    "\n",
    "Sales and Production Peaks: The peak sales figures on 2023-12-31 align with increased production and higher quality scores for various beer styles, especially Sour and Pilsner.\n",
    "\n",
    "Quality and Volume Correlation: Beer styles with high total sales on 2023-12-31 (like Sour and Pilsner) also had some of the highest quality scores, which indicates a strong positive correlation between quality and sales.\n",
    "\n",
    "Beer Preferences: Ale and IPA are the more commonly produced beer styles, while Sour and Porter might have smaller but more targeted batches, with high-quality ratings."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6b7e268-be0c-4dd0-9fd2-87bc253a772e",
   "metadata": {},
   "source": [
    "4 Machine Learning Model (Regression/Classification)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d02686c-32fe-4d75-af37-9301bffc7a2d",
   "metadata": {},
   "source": [
    "4.1 Choose the appropriate ML problem based on the dataset:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b269fe9-6add-4fb5-ae77-7442f15d5461",
   "metadata": {},
   "source": [
    "Justification for Regression Model Selection\n",
    "I'm selecting a regression model to predict Total Sales because:\n",
    "\n",
    "Nature of the Target Variable (Total Sales):\n",
    "\n",
    "Total Sales is a continuous numeric value, making it a natural fit for regression. The goal is to predict a specific value that can take on any numeric value within a range, which is a hallmark of regression problems.\n",
    "\n",
    "The primary objective is to predict Total Sales based on various influencing factors such as Beer Style, Number of Batches, and Average Quality Score. This prediction can provide valuable insights for forecasting, budget allocation, and sales strategy, making it a key decision-making tool.\n",
    "Using regression allows us to generate continuous predictions for total sales, which can be leveraged to adjust strategies in real-time based on predicted values.\n",
    "\n",
    "Predictive Power:\n",
    "\n",
    "Since Total Sales is directly influenced by multiple continuous features (e.g., Beer Style Count, Average Alcohol Content, Brew_Date, etc.), regression models are well-suited to capture these relationships and provide accurate numerical predictions. This can help in resource planning, inventory management, and understanding demand trends.\n",
    "Given this, the regression approach is optimal for our dataset, where we want to predict the Total Sales based on a variety of features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e567082-2842-4055-bae4-9f1a679ad303",
   "metadata": {},
   "source": [
    "Model: Random Forest Regressor\n",
    "\n",
    "Random Forest Regressor for the following reasons:\n",
    "\n",
    "Handles Non-linearity: The relationships between Total Sales and features like Beer Style Count, Average Quality Score, and Number of Batches may be complex and non-linear. Random Forest can capture these complex relationships, unlike linear models.\n",
    "\n",
    "Robustness: It is less prone to overfitting compared to a single decision tree, as it uses an ensemble of trees. This makes it a more robust choice when dealing with real-world, noisy data.\n",
    "\n",
    "Feature Importance: Random Forest provides insights into feature importance, which can help identify which features contribute most to predicting Total Sales, aiding in business decisions.\n",
    "\n",
    "Accuracy: It generally provides better predictive accuracy compared to simpler models like linear regression, especially for more complex problems with multiple interacting features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a956a2d0-42e3-42f8-8e4c-8be49146ec08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pyspark.sql.dataframe.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "print(type(df_cleaned))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "884c9e9b-2f0a-48dc-a94e-e2bfade7bd35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+----------+----+------------+-----------------+------------------+------------------+------------------+-----------------+----------+-----+----------------+---------------+------------------+-----------------+--------------------+-------------------+------------------------+----------------------------+\n",
      "|Batch_ID| Brew_Date|Beer_Style| SKU|    Location|Fermentation_Time|       Temperature|          pH_Level|           Gravity|  Alcohol_Content|Bitterness|Color|Ingredient_Ratio|Volume_Produced|       Total_Sales|    Quality_Score|Brewhouse_Efficiency|Loss_During_Brewing|Loss_During_Fermentation|Loss_During_Bottling_Kegging|\n",
      "+--------+----------+----------+----+------------+-----------------+------------------+------------------+------------------+-----------------+----------+-----+----------------+---------------+------------------+-----------------+--------------------+-------------------+------------------------+----------------------------+\n",
      "| 7870796|2020-01-01|Wheat Beer|Kegs|  Whitefield|               16|24.204250857069873|5.2898454476095615|1.0395041267301979|5.370842159553436|        20|    5|     1:0.32:0.16|           4666|2664.7593448382822| 8.57701633109399|   89.19588216376087| 4.1049876591878345|      3.2354851724654683|           4.663204448186049|\n",
      "| 9810411|2020-01-01|      Sour|Kegs|  Whitefield|               13|18.086762947259544| 5.275643382756193|1.0598189516987164|5.096053082797625|        36|   14|     1:0.39:0.24|            832| 9758.801062471319|7.420540752553908|    72.4809153900275| 2.6765280953921122|      4.2461292104108574|            2.04435836917023|\n",
      "| 2623342|2020-01-01|Wheat Beer|Kegs| Malleswaram|               12|15.539332669116469|4.7780156232459765|1.0374757095487201|4.824737120959184|        30|   10|     1:0.35:0.16|           2115|11721.087016274963|8.451364886803127|   86.32214396020584|  3.299893625514981|       3.109440467362847|          3.0338798378762806|\n",
      "| 8114651|2020-01-01|       Ale|Kegs| Rajajinagar|               17| 16.41848910394318| 5.345260585546188|1.0524314251694946|5.509243080797997|        48|   18|     1:0.35:0.15|           3173|12050.177463190277|9.671859404043175|   83.09494037181545|  2.136055116262562|       4.634254174098425|          1.4898890677148424|\n",
      "| 4579587|2020-01-01|     Stout|Cans|Marathahalli|               18|19.144907654338517|  4.86185374113861|1.0542961149482333|5.133624684263243|        57|   13|     1:0.46:0.11|           4449|5515.0774647529615|7.895333676172065|   88.62583302052388|  4.491723843594972|      2.1833886016455497|          2.9906302188791485|\n",
      "+--------+----------+----------+----+------------+-----------------+------------------+------------------+------------------+-----------------+----------+-----+----------------+---------------+------------------+-----------------+--------------------+-------------------+------------------------+----------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_cleaned.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffe86592-62ea-4e52-a1a9-dab03e67d419",
   "metadata": {},
   "source": [
    "Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e54ad6c8-e117-4069-97b8-b2c9e75e20c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting time-related features from Brew_Date\n",
    "df_cleaned = df_cleaned.withColumn('Brew_Year', year(col('Brew_Date')))\n",
    "df_cleaned = df_cleaned.withColumn('Brew_Month', month(col('Brew_Date')))\n",
    "df_cleaned = df_cleaned.withColumn('Brew_Day_of_Week', dayofweek(col('Brew_Date')))\n",
    "df_cleaned = df_cleaned.withColumn('Brew_Day_of_Year', dayofyear(col('Brew_Date')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f8d65c84-b144-46df-9e1a-32b869dc2256",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregating data by Beer Style to create new features\n",
    "beer_style_agg = df_cleaned.groupBy('Beer_Style').agg(\n",
    "    count('Batch_ID').alias('Number_of_Batches'),\n",
    "    avg('Quality_Score').alias('Average_Quality_Score'),\n",
    "    avg('Alcohol_Content').alias('Average_Alcohol_Content'),\n",
    "    avg('Volume_Produced').alias('Average_Volume_Produced'),\n",
    "    avg('Total_Sales').alias('Average_Sales')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "510005e0-5e50-4225-9586-bfdb9a3b00a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Joining the aggregated data back to the main dataframe\n",
    "df_cleaned = df_cleaned.join(beer_style_agg, on='Beer_Style', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "41166375-8097-4352-8971-712e39005303",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the relevant columns to create the new dataframe\n",
    "columns_to_keep = [\n",
    "    'Brew_Year', 'Brew_Month', 'Volume_Produced',\n",
    "    'Number_of_Batches', 'Total_Sales'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e87d8f79-5bc8-4c1c-a6af-37dbaa01e069",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a new DataFrame with the selected columns\n",
    "selected_df = df_cleaned.select(*columns_to_keep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ec3e09ce-b86d-4958-a6bd-485c5c5e613a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+---------------+-----------------+------------------+\n",
      "|Brew_Year|Brew_Month|Volume_Produced|Number_of_Batches|       Total_Sales|\n",
      "+---------+----------+---------------+-----------------+------------------+\n",
      "|     2020|         1|           3173|          1251002|12050.177463190277|\n",
      "|     2020|         1|           4449|          1250296|5515.0774647529615|\n",
      "|     2020|         1|           3752|          1251002| 6278.389850288936|\n",
      "|     2020|         1|            832|          1250307| 9758.801062471319|\n",
      "|     2020|         1|           4666|          1249023|2664.7593448382822|\n",
      "+---------+----------+---------------+-----------------+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Show the new DataFrame with the added features\n",
    "selected_df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81386968-893e-4667-97e2-75fb517fc0d5",
   "metadata": {},
   "source": [
    "Feature Engineering "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b44c308d-3d8a-4e8a-aeb6-4bd6de607aab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----------------+-------------------+------------+\n",
      "|Brew_Year|     Yearly_Sales|Previous_Year_Sales|Sales_Growth|\n",
      "+---------+-----------------+-------------------+------------+\n",
      "|     2020|26,307,637,143.99|               NULL|        NULL|\n",
      "|     2021|26,234,643,027.70|  26,307,637,143.99|     -0.0028|\n",
      "|     2022|26,215,935,205.80|  26,234,643,027.70|     -0.0007|\n",
      "|     2023|26,219,638,061.92|  26,215,935,205.80|      0.0001|\n",
      "+---------+-----------------+-------------------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Group by Brew_Year and calculate total sales per year\n",
    "df_yearly_sales = selected_df.groupBy(\"Brew_Year\").agg(F.sum(\"Total_Sales\").alias(\"Yearly_Sales\"))\n",
    "\n",
    "# Step 2: Create a window specification to calculate the previous year's sales\n",
    "window_spec = Window.orderBy(\"Brew_Year\")\n",
    "\n",
    "# Step 3: Add a column for the previous year's sales using the lag function\n",
    "df_yearly_sales = df_yearly_sales.withColumn(\"Previous_Year_Sales\", F.lag(\"Yearly_Sales\", 1).over(window_spec))\n",
    "\n",
    "# Step 4: Calculate the sales growth rate: (Current Year Sales - Previous Year Sales) / Previous Year Sales\n",
    "df_yearly_sales = df_yearly_sales.withColumn(\"Sales_Growth\",\n",
    "                                             (df_yearly_sales[\"Yearly_Sales\"] - df_yearly_sales[\"Previous_Year_Sales\"]) \n",
    "                                             / df_yearly_sales[\"Previous_Year_Sales\"])\n",
    "\n",
    "# Step 5: Handle edge case where there's no previous year (e.g., set Sales_Growth to null for the first year)\n",
    "df_yearly_sales = df_yearly_sales.withColumn(\"Sales_Growth\",\n",
    "                                             F.when(F.col(\"Previous_Year_Sales\").isNull(), None)\n",
    "                                             .otherwise(df_yearly_sales[\"Sales_Growth\"]))\n",
    "\n",
    "# Format columns to display with fewer decimal places for readability\n",
    "df_yearly_sales = df_yearly_sales.select(\n",
    "    \"Brew_Year\",\n",
    "    F.format_number(\"Yearly_Sales\", 2).alias(\"Yearly_Sales\"),\n",
    "    F.format_number(\"Previous_Year_Sales\", 2).alias(\"Previous_Year_Sales\"),\n",
    "    F.format_number(\"Sales_Growth\", 4).alias(\"Sales_Growth\")\n",
    ")\n",
    "\n",
    "# Show the result\n",
    "df_yearly_sales.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b72d6d4-dda4-41c6-ba63-4efd368bde5c",
   "metadata": {},
   "source": [
    "The purpose of calculating year-over-year sales growth is to assess how sales have changed over time, which provides valuable insights into the performance and trends of the business. Here's a brief description of why this step is important:\n",
    "\n",
    "Trend Analysis: Calculating sales growth helps identify whether sales are increasing or decreasing over the years. A positive growth rate indicates improvement, while a negative growth rate suggests a decline. Understanding these trends is crucial for making informed decisions about production, marketing, and strategy.\n",
    "\n",
    "Business Health: Monitoring the sales growth rate over multiple years helps evaluate the overall health and performance of the business. Consistent growth is a sign of success, while a decline could indicate issues that need to be addressed.\n",
    "\n",
    "Planning and Forecasting: By knowing how sales are growing or shrinking, businesses can plan more effectively. If there’s a consistent upward trend, businesses may decide to increase production, invest in new markets, or expand operations. Conversely, if sales are declining, it could prompt a reevaluation of business strategies or product offerings.\n",
    "\n",
    "Comparison Across Years: The lag function allows for comparing sales from one year to the next, helping highlight seasonal or annual changes that may not be apparent in the overall sales data.\n",
    "\n",
    "In summary, this analysis helps track and understand sales performance over time, which is essential for making strategic business decisions, budgeting, and predicting future performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97852211-b277-4f80-b478-ff1644e82106",
   "metadata": {},
   "source": [
    "VectorAssembler: Combine all features into a single vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0fd67acd-6286-4d12-8982-4605493abd5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------------------+\n",
      "|Brew_Year|            features|\n",
      "+---------+--------------------+\n",
      "|     2020|[1.0,1475.0,12507...|\n",
      "|     2020|[1.0,1459.0,12507...|\n",
      "|     2020|[1.0,3341.0,12507...|\n",
      "|     2020|[1.0,4642.0,12507...|\n",
      "|     2020|[1.0,3073.0,12507...|\n",
      "+---------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "# Define the feature columns you want to combine into the vector\n",
    "feature_columns = [\n",
    "    'Brew_Month', 'Volume_Produced', 'Number_of_Batches'\n",
    "]\n",
    "\n",
    "# Initialize VectorAssembler with the feature columns and the output vector column name\n",
    "assembler = VectorAssembler(inputCols=feature_columns, outputCol=\"features\")\n",
    "\n",
    "# Transform the DataFrame to add the \"features\" column\n",
    "assembled_df = assembler.transform(selected_df)\n",
    "\n",
    "# Show the DataFrame with the new \"features\" column\n",
    "assembled_df.select(\"Brew_Year\", \"features\").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b5ba84b-20b6-4929-a885-8a914c91d233",
   "metadata": {},
   "source": [
    "The VectorAssembler is used in machine learning workflows to combine multiple individual feature columns into a single vector column. This is necessary because most machine learning algorithms in Spark (and other ML frameworks) expect input data in a specific format—typically as a single column of vectors, where each vector represents a row of feature values.\n",
    "\n",
    "Reasons for using VectorAssembler:\n",
    "Required Input Format: Machine learning algorithms in Spark expect a single column containing a vector for the features, rather than multiple columns. The VectorAssembler consolidates all the feature columns (e.g., numerical, categorical) into a single vector column.\n",
    "\n",
    "Simplicity and Efficiency: It simplifies data manipulation, especially when working with many features. Rather than manually combining each feature, VectorAssembler automatically handles this process, saving time and reducing errors.\n",
    "\n",
    "Facilitates Model Training: Once the features are assembled into a vector, they can be directly fed into Spark’s machine learning models like regression, classification, and clustering. Without this step, these models would not be able to accept the input data.\n",
    "\n",
    "In essence, the VectorAssembler prepares the data for use in machine learning algorithms by transforming it into the required vector format, making it a crucial step in most Spark ML workflows."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36d59d5e-7ca1-4c15-b769-ed069b0963e5",
   "metadata": {},
   "source": [
    "Model evaluation: Evaluate the model using metrics such as RMSE for regression or\r\n",
    "accuracy/F1-score for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ced9431b-9051-40cc-b825-0aac52854faf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------------------+------------------------------------------------------------+\n",
      "|Brew_Year|Total_Sales       |scaled_features                                             |\n",
      "+---------+------------------+------------------------------------------------------------+\n",
      "|2020     |17473.8825235854  |[-1.6011815790750519,-0.9807192706752805,1.1834451215253379]|\n",
      "|2020     |6824.2626567713705|[-1.6011815790750519,-0.9930356969089057,1.1834451215253379]|\n",
      "|2020     |15380.29733887055 |[-1.6011815790750519,0.4556839388212486,1.1834451215253379] |\n",
      "|2020     |2880.503193567716 |[-1.6011815790750519,1.4571633469428908,1.1834451215253379] |\n",
      "|2020     |17806.932180755524|[-1.6011815790750519,0.2493837994080279,1.1834451215253379] |\n",
      "+---------+------------------+------------------------------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+---------+------------------+------------------+\n",
      "|Brew_Year|        prediction|       Total_Sales|\n",
      "+---------+------------------+------------------+\n",
      "|     2020| 10495.37030525703|1000.0134352860266|\n",
      "|     2020|10506.021927472899|1000.0383832416472|\n",
      "|     2020|10502.090778987487|1000.0549495561056|\n",
      "|     2020|10501.036104719684|1000.1234760987548|\n",
      "|     2020|10498.875555429748|1000.2090171673718|\n",
      "+---------+------------------+------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "Root Mean Squared Error (RMSE) on test data: 5485.390081316501\n",
      "R2 on test data: -2.6402767749900136e-07\n"
     ]
    }
   ],
   "source": [
    "# Feature Scaling: Scale the \"features\" column and output to \"scaled_features\"\n",
    "scaler = StandardScaler(inputCol=\"features\", outputCol=\"scaled_features\", withStd=True, withMean=True)\n",
    "scaled_df = scaler.fit(assembled_df).transform(assembled_df)\n",
    "\n",
    "# Retain 'Brew_Year' and 'Total_Sales' columns in scaled_df for reference in predictions\n",
    "scaled_df = scaled_df.select(\"Brew_Year\", \"Total_Sales\", \"scaled_features\")\n",
    "\n",
    "# Show the DataFrame with the \"scaled_features\" column for verification\n",
    "scaled_df.show(5, truncate=False)\n",
    "\n",
    "# Split the data into training and test sets\n",
    "train_data, test_data = scaled_df.randomSplit([0.8, 0.2], seed=42)\n",
    "\n",
    "# Initialize and train the RandomForest model\n",
    "rf = RandomForestRegressor(featuresCol=\"scaled_features\", labelCol=\"Total_Sales\")\n",
    "rf_model = rf.fit(train_data)\n",
    "\n",
    "# Make predictions on the test data\n",
    "predictions = rf_model.transform(test_data)\n",
    "\n",
    "# Show some of the predictions with 'Brew_Year' included\n",
    "predictions.select(\"Brew_Year\", \"prediction\", \"Total_Sales\").show(5)\n",
    "\n",
    "# Evaluate the model using RMSE\n",
    "evaluator = RegressionEvaluator(labelCol=\"Total_Sales\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "rmse = evaluator.evaluate(predictions)\n",
    "print(f\"Root Mean Squared Error (RMSE) on test data: {rmse}\")\n",
    "\n",
    "# Optionally, evaluate the model using R2\n",
    "r2 = evaluator.setMetricName(\"r2\").evaluate(predictions)\n",
    "print(f\"R2 on test data: {r2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf4ba114-3296-45ae-b78b-8b398b6bb043",
   "metadata": {},
   "source": [
    "Cross-validation and hyperparameter tuning to optimize the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "38bb6e34-031c-4f22-9a67-b38cff115154",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the RandomForestRegressor\n",
    "rf = RandomForestRegressor(featuresCol=\"scaled_features\", labelCol=\"Total_Sales\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b2f3fe43-fbe9-4c30-b483-757e790d8e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a parameter grid for tuning\n",
    "param_grid = (ParamGridBuilder()\n",
    "              .addGrid(rf.numTrees, [50, 100, 200])  # Number of trees\n",
    "              .addGrid(rf.maxDepth, [5, 10, 15])    # Maximum depth of trees\n",
    "              .addGrid(rf.minInstancesPerNode, [1, 5, 10])  # Minimum number of instances per node\n",
    "              .build())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "70b13133-513e-43ba-9a6a-14e2e79b9fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the evaluator\n",
    "evaluator = RegressionEvaluator(labelCol=\"Total_Sales\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "\n",
    "# Set up the CrossValidator\n",
    "crossval = CrossValidator(estimator=rf, \n",
    "                          estimatorParamMaps=param_grid, \n",
    "                          evaluator=evaluator, \n",
    "                          numFolds=5,  # 5-fold cross-validation\n",
    "                          seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "35a3ca4e-d07d-4f77-b8ac-5f4f14449c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform cross-validation and get the best model\n",
    "cv_model = crossval.fit(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9ab6bb3a-9827-4c7a-8217-10cb677a552d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the best model from cross-validation\n",
    "best_rf_model = cv_model.bestModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "01a1aa9f-926b-4794-9fed-d01e8628e69d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions using the best model\n",
    "predictions = best_rf_model.transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4e58f12c-0fe9-4f44-97fb-66253a9328eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------------------+------------------+\n",
      "|Brew_Year|        prediction|       Total_Sales|\n",
      "+---------+------------------+------------------+\n",
      "|     2020|10501.475343170161|1000.0134352860266|\n",
      "|     2020|10502.991538466043|1000.0383832416472|\n",
      "|     2020|10501.262749325395|1000.0549495561056|\n",
      "|     2020|10497.836105780634|1000.1234760987548|\n",
      "|     2020|10516.656545008076|1000.2090171673718|\n",
      "+---------+------------------+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Show some of the predictions with 'Brew_Year' included\n",
    "predictions.select(\"Brew_Year\", \"prediction\", \"Total_Sales\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "bad0bf10-01a9-43ac-beea-1233a26a70ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error (RMSE) on test data: 5485.390862021014\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model using RMSE\n",
    "rmse = evaluator.evaluate(predictions)\n",
    "print(f\"Root Mean Squared Error (RMSE) on test data: {rmse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a0421ae9-51e8-4bfb-8956-4b6b1ac77601",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 on test data: -5.4867644938561e-07\n"
     ]
    }
   ],
   "source": [
    "# Optionally, evaluate the model using R2\n",
    "r2 = evaluator.setMetricName(\"r2\").evaluate(predictions)\n",
    "print(f\"R2 on test data: {r2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d11537a4-6d7b-450b-8e07-f939926a4d97",
   "metadata": {},
   "source": [
    "The R² value close to zero (and slightly negative) suggests that the model explains almost none of the variance in Total_Sales.\n",
    "\n",
    "\n",
    "An R² near zero can occur when the features used in the model don’t have a strong relationship with the target variable (Total_Sales). This could imply that your features (like Brew_Year, Volume_Produced, Number_of_Batches, etc.) aren’t sufficient to predict Total_Sales accurately.\n",
    "\n",
    "More exploration and improvements will be implemented in order to obtain a better value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b1d1400-b004-4fde-9fe7-63688c9fc5f8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
